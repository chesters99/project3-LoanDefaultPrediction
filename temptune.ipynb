{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "from scipy.stats import skew\n",
    "\n",
    "np.warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "\n",
    "# set Jupyter to display ALL output from a cell (not just last output)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "\n",
    "# set pandas and numpy options to make print format nicer\n",
    "pd.set_option(\"display.width\",100)\n",
    "pd.set_option(\"display.max_columns\",1000)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "np.set_printoptions(linewidth=120, threshold=5000, edgeitems=50, suppress=True)\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: loan_stat542.csv into loans dataframe...\n",
      "Loans dataframe: (844006, 30)\n",
      "ids dataframe: (253200, 3)\n",
      "Fold 0 (590806, 30) (253200, 29) (253200, 2)\n",
      "Fold 1 (590806, 30) (253200, 29) (253200, 2)\n",
      "Fold 2 (590806, 30) (253200, 29) (253200, 2)\n",
      "Writing train, test, labels csv files...\n",
      "Done!\n",
      "CPU times: user 3.84 s, sys: 468 ms, total: 4.3 s\n",
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Reading: loan_stat542.csv into loans dataframe...')\n",
    "\n",
    "loans = pd.read_csv('loan_stat542.csv')\n",
    "print('Loans dataframe:', loans.shape)\n",
    "\n",
    "test_ids = pd.read_csv('Project3_test_id.csv', dtype={'test1':int,'test2':int, 'test3':int,})\n",
    "print('ids dataframe:', test_ids.shape)\n",
    "\n",
    "trains = []\n",
    "tests = []\n",
    "labels = []\n",
    "for i, col in enumerate(test_ids.columns):\n",
    "    trains.append(loans.loc[~loans.id.isin(test_ids[col]),:])\n",
    "    tests.append( loans.loc[ loans.id.isin(test_ids[col]), loans.columns!='loan_status'])\n",
    "    labels.append(loans.loc[ loans.id.isin(test_ids[col]), ['id','loan_status']])\n",
    "    labels[i][\"y\"] = (labels[i].loan_status != 'Fully Paid').astype(int)\n",
    "    labels[i].drop('loan_status', axis=1, inplace=True)\n",
    "    print('Fold', i, trains[i].shape, tests[i].shape, labels[i].shape)\n",
    "\n",
    "print('Writing train, test, labels csv files...')\n",
    "# fold=0\n",
    "# _ = trains[fold].to_csv('train.csv', index=False)\n",
    "# _ = tests [fold].to_csv('test.csv',  index=False)\n",
    "# _ = labels[fold].to_csv('label.csv', index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data):        \n",
    "    data['emp_length'] = data.emp_length.fillna('Unknown').str.replace('<','LT')\n",
    "    data['dti'] = data.dti.fillna(0)\n",
    "    data['revol_util'] = data.revol_util.fillna(0)\n",
    "    data['mort_acc'] = data.mort_acc.fillna(0)\n",
    "    data['pub_rec_bankruptcies'] = data.pub_rec_bankruptcies.fillna(0)\n",
    "    temp = pd.to_datetime(data.earliest_cr_line)\n",
    "    data['earliest_cr_line'] = temp.dt.year*12 - 1950*12 + temp.dt.month\n",
    "    data.drop(['emp_title','title','zip_code','grade','fico_range_high'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def logloss(y, p):\n",
    "    loglosses = np.where(y==1, -np.log(p+1e-15), -np.log(1-p+1e-15))\n",
    "    return np.mean(loglosses)\n",
    "\n",
    "def prep_train_test(train, test):    \n",
    "    train = process(train)\n",
    "    X_train = train.drop(['loan_status'], axis=1)\n",
    "    X_train = pd.get_dummies(X_train) # create dataframe with dummy variables replacing categoricals\n",
    "    X_train = X_train.reindex(sorted(X_train.columns), axis=1) # sort columns to be in same sequence as test\n",
    "    y_train = (train.loan_status!='Fully Paid').astype(int)\n",
    "\n",
    "    test = process(test)\n",
    "    X_test = pd.get_dummies(test) # create dataframe with dummy variables replacing categoricals\n",
    "\n",
    "    all_columns = X_train.columns.union(X_test.columns) # add columns to test that are in train but not test\n",
    "    X_test = X_test.reindex(columns=all_columns).fillna(0)\n",
    "    X_test = X_test.reindex(sorted(X_train.columns), axis=1) # sort columns to be in same sequence at train\n",
    "\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590806, 30)\n",
      "(590806, 142) (590806,) (253200, 142)\n"
     ]
    }
   ],
   "source": [
    "train = trains[0].copy()\n",
    "test = tests[0].copy()\n",
    "label = labels[0].copy()\n",
    "fraction = 1\n",
    "if fraction < 1:\n",
    "    train = train.sample(frac=fraction, random_state=seed)\n",
    "    test  = test.sample(frac=fraction, random_state=seed)\n",
    "print(train.shape)\n",
    "X_train, y_train, X_test = prep_train_test(train, test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params = {\n",
    "      'learning_rate':      np.linspace(0.04, 0.08, 9),\n",
    "      'n_estimators':       np.linspace(540, 1000, 24, dtype=int),\n",
    "      'max_depth':          np.linspace(4, 10, 7, dtype=int),  \n",
    "      'min_samples_split':  np.linspace(2, 6, 5, dtype=int),\n",
    "      'min_samples_leaf':   np.linspace(2, 6, 5, dtype=int),    \n",
    "      'min_weight_fraction_leaf': np.linspace(0, 0.05, 2),\n",
    "      'subsample':          np.linspace(0.8, 1, 5),\n",
    "      'max_features':       ('sqrt',), \n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "      'learning_rate':    np.linspace(0.01, 0.07, 13), \n",
    "      'n_estimators':     np.linspace(300, 900, 13, dtype=int),\n",
    "      'min_child_weight': np.linspace(5, 9, 5, dtype=int), \n",
    "      'max_depth':        np.linspace(4, 9, 6, dtype=int), \n",
    "      'gamma':            np.linspace(0, 0.5, 11), \n",
    "      'subsample':        np.linspace(0.5, 1, 11),  \n",
    "      'colsample_bytree': np.linspace(0.8, 1, 5),\n",
    "      'reg_lambda':       np.linspace(0.6, 1, 9), \n",
    "      'reg_alpha':        np.linspace(0, 0.5, 11), \n",
    "      'silent':           [1,],\n",
    "}\n",
    "\n",
    "# base_model = GradientBoostingClassifier(random_state=seed)\n",
    "base_model = xgb.XGBClassifier(n_estimators=150, objective= 'binary:logistic', random_state=seed, n_jobs=-1)\n",
    "model = RandomizedSearchCV(base_model,n_iter=300,n_jobs=2, cv=ShuffleSplit(test_size=0.20,n_splits=1,random_state=0), \n",
    "                           param_distributions=xgb_params,scoring='neg_log_loss',\n",
    "                           verbose=10, random_state=seed, return_train_score=False)\n",
    "\n",
    "_ = model.fit(X_train, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.best_params_)\n",
    "print(-round(model.best_score_,6))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(model.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "df.loc[:,df.columns!='params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize, gbrt_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "import datetime, warnings\n",
    "\n",
    "def objective(values):    \n",
    "    index = str(values)\n",
    "    if index in cache:\n",
    "        print('GET FROM CACHE:', index, round(cache[index],4))\n",
    "        return cache[index]\n",
    "    if model_type == 'LogisticRegression':\n",
    "        params = {'penalty': values[0], 'C': values[1],}\n",
    "        model = LogisticRegression(**params, random_state=seed, n_jobs=-1)\n",
    "        \n",
    "#     if model_type == 'RandomForestClassifier':\n",
    "#         params = {'n_estimators': values[0], 'max_features': values[1], 'max_depth': values[2],}\n",
    "#         model = RandomForestClassifier(**params, n_jobs=-1)\n",
    "    \n",
    "    if model_type == 'GradientBoostingClassifier':\n",
    "        params = {'learning_rate': values[0], 'n_estimators': values[1], 'max_depth': values[2],\n",
    "                  'min_samples_split': values[3], 'min_samples_leaf': values[4], \n",
    "                  'min_weight_fraction_leaf' : values[5], 'subsample': values[6], 'max_features': values[7] }\n",
    "        model = GradientBoostingClassifier(**params, random_state=seed)\n",
    "    \n",
    "    if model_type == 'XGBClassifier':\n",
    "        params = {'learning_rate': values[0], 'n_estimators': int(values[1]), 'min_child_weight': int(values[2]),\n",
    "                  'max_depth': int(values[3]), 'gamma': values[4], 'subsample': values[5],\n",
    "                  'colsample_bytree': values[6], 'lambda': values[7], 'alpha': values[8], 'eval_metric':'logloss'}\n",
    "        model = xgb.XGBClassifier(**params, random_state=seed, n_jobs=8,silent=1)\n",
    "        \n",
    "    print(datetime.datetime.now().time().replace(microsecond=0), ', Params',params) \n",
    "#     scores = -cross_val_score(model, X_train, y_train, scoring=\"neg_log_loss\", cv=5, n_jobs=-1)\n",
    "    _ = model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_test)[:,1]\n",
    "    y_test = pd.merge(test[['id']], label, how='left', on='id')\n",
    "\n",
    "    cache[index] = np.mean( logloss(y_test.y, probs) )\n",
    "    return cache[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "11:20:05 , Params {'learning_rate': 0.032472407130841756, 'n_estimators': 570, 'min_child_weight': 7, 'max_depth': 8, 'gamma': 0.29842507897324355, 'subsample': 0.7229163764267956, 'colsample_bytree': 0.8199949831636006, 'lambda': 0.7836995567863468, 'alpha': 0.16685430556951095, 'eval_metric': 'logloss'}\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 447.0242\n",
      "Function value obtained: 0.4393\n",
      "Current minimum: 0.4393\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "11:27:32 , Params {'learning_rate': 0.018572009075316448, 'n_estimators': 430, 'min_child_weight': 9, 'max_depth': 5, 'gamma': 0.3609993861334124, 'subsample': 0.9692763545078752, 'colsample_bytree': 0.8001557531682029, 'lambda': 0.996884623716487, 'alpha': 0.3087407548138583, 'eval_metric': 'logloss'}\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 184.5864\n",
      "Function value obtained: 0.4439\n",
      "Current minimum: 0.4393\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "11:30:36 , Params {'learning_rate': 0.04669918962929686, 'n_estimators': 552, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.14561457009902098, 'subsample': 0.8059264473611898, 'colsample_bytree': 0.8278987721304084, 'lambda': 0.7168578594140873, 'alpha': 0.18318092164684588, 'eval_metric': 'logloss'}\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 213.3094\n",
      "Function value obtained: 0.4413\n",
      "Current minimum: 0.4393\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "11:34:10 , Params {'learning_rate': 0.037364199053022164, 'n_estimators': 862, 'min_child_weight': 8, 'max_depth': 7, 'gamma': 0.2962072844310213, 'subsample': 0.5232252063599989, 'colsample_bytree': 0.9215089703802877, 'lambda': 0.6682096494749166, 'alpha': 0.032525796492639765, 'eval_metric': 'logloss'}\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 684.0826\n",
      "Function value obtained: 0.4390\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "11:45:34 , Params {'learning_rate': 0.0669331322352, 'n_estimators': 615, 'min_child_weight': 6, 'max_depth': 5, 'gamma': 0.15230688458668537, 'subsample': 0.5488360570031919, 'colsample_bytree': 0.9368466053024314, 'lambda': 0.7760609974958406, 'alpha': 0.06101911742238943, 'eval_metric': 'logloss'}\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 344.0940\n",
      "Function value obtained: 0.4396\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "11:51:18 , Params {'learning_rate': 0.039612794820407124, 'n_estimators': 817, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.39114738228789775, 'subsample': 0.5297860772180321, 'colsample_bytree': 0.9104091604426923, 'lambda': 0.6518344268507689, 'alpha': 0.025768892816983198, 'eval_metric': 'logloss'}\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 786.6082\n",
      "Function value obtained: 0.4397\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "12:04:25 , Params {'learning_rate': 0.028171385913113203, 'n_estimators': 868, 'min_child_weight': 7, 'max_depth': 8, 'gamma': 0.1399151764524502, 'subsample': 0.5105537312591736, 'colsample_bytree': 0.9717820488325419, 'lambda': 0.7328192598050536, 'alpha': 0.13784916014174478, 'eval_metric': 'logloss'}\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 803.9329\n",
      "Function value obtained: 0.4390\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "12:17:49 , Params {'learning_rate': 0.013352884549298213, 'n_estimators': 390, 'min_child_weight': 9, 'max_depth': 7, 'gamma': 0.4794205912442671, 'subsample': 0.8965198704117161, 'colsample_bytree': 0.9269415523023449, 'lambda': 0.8929965723908371, 'alpha': 0.4576996600504654, 'eval_metric': 'logloss'}\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 274.5159\n",
      "Function value obtained: 0.4436\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "12:22:23 , Params {'learning_rate': 0.01605752479227608, 'n_estimators': 884, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.2718888181990053, 'subsample': 0.9112255371225326, 'colsample_bytree': 0.944490606645503, 'lambda': 0.8424692540408656, 'alpha': 0.09455362457032992, 'eval_metric': 'logloss'}\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 761.1580\n",
      "Function value obtained: 0.4397\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "12:35:04 , Params {'learning_rate': 0.044676178119060654, 'n_estimators': 431, 'min_child_weight': 8, 'max_depth': 9, 'gamma': 0.25411300494169925, 'subsample': 0.520606743565454, 'colsample_bytree': 0.8075511663774058, 'lambda': 0.6598749359933285, 'alpha': 0.08619419661392498, 'eval_metric': 'logloss'}\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 352.6726\n",
      "Function value obtained: 0.4397\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "12:40:57 , Params {'learning_rate': 0.056164504748053144, 'n_estimators': 573, 'min_child_weight': 7, 'max_depth': 8, 'gamma': 0.10912753637347425, 'subsample': 0.5025567863832433, 'colsample_bytree': 0.8010923735412887, 'lambda': 0.8941923568252677, 'alpha': 0.3091801558645695, 'eval_metric': 'logloss'}\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 470.2347\n",
      "Function value obtained: 0.4397\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "12:48:47 , Params {'learning_rate': 0.04431571441632242, 'n_estimators': 401, 'min_child_weight': 9, 'max_depth': 6, 'gamma': 0.15692041389851438, 'subsample': 0.5164334741686463, 'colsample_bytree': 0.9972582207110791, 'lambda': 0.9723560152262072, 'alpha': 0.030022267963875367, 'eval_metric': 'logloss'}\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 307.0612\n",
      "Function value obtained: 0.4403\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "12:53:54 , Params {'learning_rate': 0.02242562240602527, 'n_estimators': 611, 'min_child_weight': 8, 'max_depth': 7, 'gamma': 0.4289836598002877, 'subsample': 0.8597177736280333, 'colsample_bytree': 0.8935617434562031, 'lambda': 0.9907257637596014, 'alpha': 0.40680527721011045, 'eval_metric': 'logloss'}\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 418.0705\n",
      "Function value obtained: 0.4404\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "13:00:52 , Params {'learning_rate': 0.013656410074271864, 'n_estimators': 408, 'min_child_weight': 5, 'max_depth': 8, 'gamma': 0.346295839689176, 'subsample': 0.9602235883784526, 'colsample_bytree': 0.9601280783254214, 'lambda': 0.9503371117185225, 'alpha': 0.433886818822869, 'eval_metric': 'logloss'}\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 346.0070\n",
      "Function value obtained: 0.4425\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "13:06:38 , Params {'learning_rate': 0.04460811770349425, 'n_estimators': 484, 'min_child_weight': 6, 'max_depth': 6, 'gamma': 0.05678031431940418, 'subsample': 0.9025631737027734, 'colsample_bytree': 0.8191539397196635, 'lambda': 0.9983366759058275, 'alpha': 0.007949527274233483, 'eval_metric': 'logloss'}\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 275.8526\n",
      "Function value obtained: 0.4402\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "13:11:14 , Params {'learning_rate': 0.015030313147385283, 'n_estimators': 505, 'min_child_weight': 8, 'max_depth': 8, 'gamma': 0.03571057979276016, 'subsample': 0.9666805943084698, 'colsample_bytree': 0.873215729623183, 'lambda': 0.7907854309970331, 'alpha': 0.3527001736465057, 'eval_metric': 'logloss'}\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 422.4140\n",
      "Function value obtained: 0.4415\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "13:18:16 , Params {'learning_rate': 0.01592949862397164, 'n_estimators': 414, 'min_child_weight': 8, 'max_depth': 8, 'gamma': 0.4722957473311637, 'subsample': 0.667214087138515, 'colsample_bytree': 0.8064300549585419, 'lambda': 0.6926276404331178, 'alpha': 0.033448004215282275, 'eval_metric': 'logloss'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 325.1661\n",
      "Function value obtained: 0.4416\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "13:23:42 , Params {'learning_rate': 0.04292561806613531, 'n_estimators': 846, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.3083706706585818, 'subsample': 0.9826626429973844, 'colsample_bytree': 0.909811816338645, 'lambda': 0.6848703222450128, 'alpha': 0.01927362866821281, 'eval_metric': 'logloss'}\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 691.4619\n",
      "Function value obtained: 0.4398\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "13:35:13 , Params {'learning_rate': 0.06506569609297086, 'n_estimators': 857, 'min_child_weight': 6, 'max_depth': 8, 'gamma': 0.3427445488422126, 'subsample': 0.6506047694323046, 'colsample_bytree': 0.8005724711222457, 'lambda': 0.6201824077171363, 'alpha': 0.05586489967522863, 'eval_metric': 'logloss'}\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 643.4160\n",
      "Function value obtained: 0.4403\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "13:45:57 , Params {'learning_rate': 0.05658373799746152, 'n_estimators': 878, 'min_child_weight': 8, 'max_depth': 9, 'gamma': 0.49672346609696894, 'subsample': 0.7581717790742497, 'colsample_bytree': 0.8000622207685605, 'lambda': 0.7728222560420487, 'alpha': 0.06782754376509705, 'eval_metric': 'logloss'}\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 708.9299\n",
      "Function value obtained: 0.4404\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "13:57:45 , Params {'learning_rate': 0.010538039492754215, 'n_estimators': 407, 'min_child_weight': 9, 'max_depth': 7, 'gamma': 0.29778173066234825, 'subsample': 0.5069955519333361, 'colsample_bytree': 0.865450872649614, 'lambda': 0.6458472846195767, 'alpha': 0.46114751327171816, 'eval_metric': 'logloss'}\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 312.8916\n",
      "Function value obtained: 0.4445\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "14:02:58 , Params {'learning_rate': 0.046028228015114137, 'n_estimators': 889, 'min_child_weight': 8, 'max_depth': 7, 'gamma': 0.1778621953347557, 'subsample': 0.6066553844532139, 'colsample_bytree': 0.9902486270504814, 'lambda': 0.6512632065360177, 'alpha': 0.48242601373407357, 'eval_metric': 'logloss'}\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 1096.9061\n",
      "Function value obtained: 0.4394\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "14:21:15 , Params {'learning_rate': 0.010249778283191506, 'n_estimators': 873, 'min_child_weight': 6, 'max_depth': 5, 'gamma': 0.09688668551831534, 'subsample': 0.7307922007850552, 'colsample_bytree': 0.9368728214240245, 'lambda': 0.6737446117174926, 'alpha': 0.2628445552238194, 'eval_metric': 'logloss'}\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 817.7915\n",
      "Function value obtained: 0.4432\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "14:34:53 , Params {'learning_rate': 0.011611729289826145, 'n_estimators': 309, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.07141922153314696, 'subsample': 0.9727972382458898, 'colsample_bytree': 0.9050270733268829, 'lambda': 0.8058016988432071, 'alpha': 0.3267548951009453, 'eval_metric': 'logloss'}\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 434.1047\n",
      "Function value obtained: 0.4446\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "14:42:07 , Params {'learning_rate': 0.011447635017378761, 'n_estimators': 888, 'min_child_weight': 9, 'max_depth': 7, 'gamma': 0.09475914069775696, 'subsample': 0.9580263742454498, 'colsample_bytree': 0.8691063237725914, 'lambda': 0.6437489739476847, 'alpha': 0.35882754629602187, 'eval_metric': 'logloss'}\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 548.2470\n",
      "Function value obtained: 0.4412\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "14:51:15 , Params {'learning_rate': 0.012285656902053948, 'n_estimators': 377, 'min_child_weight': 9, 'max_depth': 6, 'gamma': 0.04723163519261454, 'subsample': 0.9700582828702071, 'colsample_bytree': 0.869648294544243, 'lambda': 0.8823264882105261, 'alpha': 0.23181440480738824, 'eval_metric': 'logloss'}\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 202.7490\n",
      "Function value obtained: 0.4453\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "14:54:38 , Params {'learning_rate': 0.027311186965507765, 'n_estimators': 387, 'min_child_weight': 6, 'max_depth': 9, 'gamma': 0.4207655950007227, 'subsample': 0.9887195977147702, 'colsample_bytree': 0.8324161448557952, 'lambda': 0.8014653874722327, 'alpha': 0.14111255012655474, 'eval_metric': 'logloss'}\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 299.9060\n",
      "Function value obtained: 0.4404\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "14:59:38 , Params {'learning_rate': 0.010823894322126338, 'n_estimators': 320, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.49964759922486934, 'subsample': 0.5685789730384845, 'colsample_bytree': 0.8366504886589864, 'lambda': 0.880402539006198, 'alpha': 0.35979818988046874, 'eval_metric': 'logloss'}\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 305.7833\n",
      "Function value obtained: 0.4445\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "15:04:44 , Params {'learning_rate': 0.011837819673098274, 'n_estimators': 349, 'min_child_weight': 9, 'max_depth': 6, 'gamma': 0.1445723936516348, 'subsample': 0.697675144175218, 'colsample_bytree': 0.9797537373119819, 'lambda': 0.7892299684709281, 'alpha': 0.16930926286284984, 'eval_metric': 'logloss'}\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 232.4722\n",
      "Function value obtained: 0.4460\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "15:08:36 , Params {'learning_rate': 0.010316856528607433, 'n_estimators': 899, 'min_child_weight': 9, 'max_depth': 6, 'gamma': 0.4082820969071005, 'subsample': 0.5724712000915875, 'colsample_bytree': 0.8753574733780256, 'lambda': 0.8285218961621803, 'alpha': 0.002874694005715939, 'eval_metric': 'logloss'}\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 560.8242\n",
      "Function value obtained: 0.4419\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "15:17:57 , Params {'learning_rate': 0.012235763306244773, 'n_estimators': 548, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.08081052248990124, 'subsample': 0.8289456494801692, 'colsample_bytree': 0.899432004972052, 'lambda': 0.684129536569669, 'alpha': 0.1536097705958532, 'eval_metric': 'logloss'}\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 213.0105\n",
      "Function value obtained: 0.4460\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "15:21:30 , Params {'learning_rate': 0.01894747014574777, 'n_estimators': 659, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.06461472169531608, 'subsample': 0.8815352902072888, 'colsample_bytree': 0.844018332846806, 'lambda': 0.7431802576207611, 'alpha': 0.4983212427774754, 'eval_metric': 'logloss'}\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 250.2166\n",
      "Function value obtained: 0.4434\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "15:25:40 , Params {'learning_rate': 0.028946695122033135, 'n_estimators': 501, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.2772257117739506, 'subsample': 0.7981611101312991, 'colsample_bytree': 0.9588188645948623, 'lambda': 0.7640001294451593, 'alpha': 0.06680363445347128, 'eval_metric': 'logloss'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 212.8185\n",
      "Function value obtained: 0.4429\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "15:29:13 , Params {'learning_rate': 0.01183149525605268, 'n_estimators': 594, 'min_child_weight': 9, 'max_depth': 5, 'gamma': 0.27721416426605866, 'subsample': 0.5675303006399686, 'colsample_bytree': 0.8903036547066469, 'lambda': 0.6371178174495238, 'alpha': 0.16005674348056873, 'eval_metric': 'logloss'}\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 326.7292\n",
      "Function value obtained: 0.4441\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "15:34:40 , Params {'learning_rate': 0.011925958532415015, 'n_estimators': 396, 'min_child_weight': 9, 'max_depth': 5, 'gamma': 0.012648565994462572, 'subsample': 0.8493241444594181, 'colsample_bytree': 0.9537416611158581, 'lambda': 0.7163978383666009, 'alpha': 0.3436890307893408, 'eval_metric': 'logloss'}\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 214.4967\n",
      "Function value obtained: 0.4465\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "15:38:14 , Params {'learning_rate': 0.04599678042687489, 'n_estimators': 699, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.0023991659704465933, 'subsample': 0.5955671287456479, 'colsample_bytree': 0.8207942723349781, 'lambda': 0.9871768896830047, 'alpha': 0.23628628194568896, 'eval_metric': 'logloss'}\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 627.8211\n",
      "Function value obtained: 0.4396\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "15:48:42 , Params {'learning_rate': 0.06516297297069994, 'n_estimators': 645, 'min_child_weight': 9, 'max_depth': 7, 'gamma': 0.0063007335564111994, 'subsample': 0.5309961208961936, 'colsample_bytree': 0.8526048104183503, 'lambda': 0.7255341053325345, 'alpha': 0.27142825209819643, 'eval_metric': 'logloss'}\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 475.7257\n",
      "Function value obtained: 0.4396\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "15:56:38 , Params {'learning_rate': 0.012597215651329442, 'n_estimators': 894, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.22562545007595047, 'subsample': 0.980469149180644, 'colsample_bytree': 0.99201041314988, 'lambda': 0.8598063524170247, 'alpha': 0.26781539355673994, 'eval_metric': 'logloss'}\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 1091.2211\n",
      "Function value obtained: 0.4402\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "16:14:49 , Params {'learning_rate': 0.012078439667212542, 'n_estimators': 322, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.00960105397410971, 'subsample': 0.9549289343939935, 'colsample_bytree': 0.8938698684310473, 'lambda': 0.7027881076312297, 'alpha': 0.4640990226240796, 'eval_metric': 'logloss'}\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 214.7443\n",
      "Function value obtained: 0.4502\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "16:18:24 , Params {'learning_rate': 0.05300831019517769, 'n_estimators': 328, 'min_child_weight': 7, 'max_depth': 6, 'gamma': 0.03350989653556547, 'subsample': 0.5640379285681308, 'colsample_bytree': 0.9933543806569972, 'lambda': 0.6853984995909982, 'alpha': 0.426180362691161, 'eval_metric': 'logloss'}\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 428.4573\n",
      "Function value obtained: 0.4403\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "16:25:32 , Params {'learning_rate': 0.04896297447548514, 'n_estimators': 325, 'min_child_weight': 7, 'max_depth': 8, 'gamma': 0.10443018450825717, 'subsample': 0.8760400150422343, 'colsample_bytree': 0.8168045778211749, 'lambda': 0.6877658000585349, 'alpha': 0.41768723928412016, 'eval_metric': 'logloss'}\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 406.3661\n",
      "Function value obtained: 0.4399\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "16:32:19 , Params {'learning_rate': 0.06837479249334037, 'n_estimators': 323, 'min_child_weight': 7, 'max_depth': 6, 'gamma': 0.4833521884510503, 'subsample': 0.9780440362056955, 'colsample_bytree': 0.8152173048456046, 'lambda': 0.7079789283781046, 'alpha': 0.4850318357682773, 'eval_metric': 'logloss'}\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 289.2329\n",
      "Function value obtained: 0.4404\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "16:37:08 , Params {'learning_rate': 0.05077970400185275, 'n_estimators': 305, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.002884555392416111, 'subsample': 0.6614919144006347, 'colsample_bytree': 0.9804679108134416, 'lambda': 0.6713174030040203, 'alpha': 0.43175865542415676, 'eval_metric': 'logloss'}\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 184.3512\n",
      "Function value obtained: 0.4426\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "16:40:12 , Params {'learning_rate': 0.052959111644286856, 'n_estimators': 314, 'min_child_weight': 7, 'max_depth': 5, 'gamma': 0.00351033101267595, 'subsample': 0.9318356276179142, 'colsample_bytree': 0.8127554615115371, 'lambda': 0.6742762570623557, 'alpha': 0.44857411927958074, 'eval_metric': 'logloss'}\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 134.2695\n",
      "Function value obtained: 0.4416\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "16:42:27 , Params {'learning_rate': 0.012120666765105741, 'n_estimators': 897, 'min_child_weight': 7, 'max_depth': 7, 'gamma': 0.22273894604479066, 'subsample': 0.8452184065616778, 'colsample_bytree': 0.8114203133075448, 'lambda': 0.7702275489177888, 'alpha': 0.4761018897179315, 'eval_metric': 'logloss'}\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 557.4888\n",
      "Function value obtained: 0.4409\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "16:51:44 , Params {'learning_rate': 0.04093917933744228, 'n_estimators': 322, 'min_child_weight': 8, 'max_depth': 9, 'gamma': 0.2856210165734401, 'subsample': 0.7159921192464007, 'colsample_bytree': 0.9548187778875467, 'lambda': 0.6919138458463175, 'alpha': 0.2871119739755865, 'eval_metric': 'logloss'}\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 326.4898\n",
      "Function value obtained: 0.4398\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "16:57:11 , Params {'learning_rate': 0.011850726689681167, 'n_estimators': 784, 'min_child_weight': 8, 'max_depth': 5, 'gamma': 0.009295952417744004, 'subsample': 0.9737006429571686, 'colsample_bytree': 0.8612760788602299, 'lambda': 0.9684835307246287, 'alpha': 0.2536395771103177, 'eval_metric': 'logloss'}\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 361.4571\n",
      "Function value obtained: 0.4434\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "17:03:12 , Params {'learning_rate': 0.011274236113741485, 'n_estimators': 567, 'min_child_weight': 7, 'max_depth': 5, 'gamma': 0.016590131414292556, 'subsample': 0.9434937128507824, 'colsample_bytree': 0.8588993609896134, 'lambda': 0.8830036310094921, 'alpha': 0.4634150078137819, 'eval_metric': 'logloss'}\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 255.9649\n",
      "Function value obtained: 0.4448\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "17:07:28 , Params {'learning_rate': 0.011853543582918255, 'n_estimators': 320, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.47124084778874104, 'subsample': 0.837649519884837, 'colsample_bytree': 0.8478188860578764, 'lambda': 0.8475645357112885, 'alpha': 0.4689286913406785, 'eval_metric': 'logloss'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 122.1584\n",
      "Function value obtained: 0.4504\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "17:09:30 , Params {'learning_rate': 0.012091066540569712, 'n_estimators': 375, 'min_child_weight': 7, 'max_depth': 5, 'gamma': 0.2666993227879508, 'subsample': 0.7574769023561233, 'colsample_bytree': 0.8647799204181779, 'lambda': 0.848164331205967, 'alpha': 0.4847526179361339, 'eval_metric': 'logloss'}\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 181.6646\n",
      "Function value obtained: 0.4467\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 51 started. Searching for the next optimal point.\n",
      "17:12:32 , Params {'learning_rate': 0.011985939362168265, 'n_estimators': 442, 'min_child_weight': 5, 'max_depth': 6, 'gamma': 0.3551130166630681, 'subsample': 0.6764143076154374, 'colsample_bytree': 0.8986002234623314, 'lambda': 0.9819184311094402, 'alpha': 0.49647698407838786, 'eval_metric': 'logloss'}\n",
      "Iteration No: 51 ended. Search finished for the next optimal point.\n",
      "Time taken: 277.3177\n",
      "Function value obtained: 0.4443\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 52 started. Searching for the next optimal point.\n",
      "17:17:09 , Params {'learning_rate': 0.01098780294469218, 'n_estimators': 302, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.4052350289896849, 'subsample': 0.9055240266065474, 'colsample_bytree': 0.9322197565231404, 'lambda': 0.995506990227317, 'alpha': 0.4819596311649616, 'eval_metric': 'logloss'}\n",
      "Iteration No: 52 ended. Search finished for the next optimal point.\n",
      "Time taken: 118.5812\n",
      "Function value obtained: 0.4522\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 53 started. Searching for the next optimal point.\n",
      "17:19:08 , Params {'learning_rate': 0.055138584476758026, 'n_estimators': 300, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.19503634250455354, 'subsample': 0.9497290150071952, 'colsample_bytree': 0.8930959602708497, 'lambda': 0.9372456065892046, 'alpha': 0.49337438441773, 'eval_metric': 'logloss'}\n",
      "Iteration No: 53 ended. Search finished for the next optimal point.\n",
      "Time taken: 248.6393\n",
      "Function value obtained: 0.4399\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 54 started. Searching for the next optimal point.\n",
      "17:23:16 , Params {'learning_rate': 0.01121002149052374, 'n_estimators': 362, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.27446315501464963, 'subsample': 0.6312899358195496, 'colsample_bytree': 0.9705858536412381, 'lambda': 0.9536333898329241, 'alpha': 0.06872244780914523, 'eval_metric': 'logloss'}\n",
      "Iteration No: 54 ended. Search finished for the next optimal point.\n",
      "Time taken: 165.0537\n",
      "Function value obtained: 0.4495\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 55 started. Searching for the next optimal point.\n",
      "17:26:01 , Params {'learning_rate': 0.010092233306375249, 'n_estimators': 300, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.37848045352972465, 'subsample': 0.6590181126260507, 'colsample_bytree': 0.9072504084330699, 'lambda': 0.9608702155592344, 'alpha': 0.002300064788332668, 'eval_metric': 'logloss'}\n",
      "Iteration No: 55 ended. Search finished for the next optimal point.\n",
      "Time taken: 129.2705\n",
      "Function value obtained: 0.4535\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n",
      "17:28:11 , Params {'learning_rate': 0.012092520930398875, 'n_estimators': 316, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.24955738765932078, 'subsample': 0.5014527481015036, 'colsample_bytree': 0.9912249826233258, 'lambda': 0.7435906256138931, 'alpha': 0.45393522200502173, 'eval_metric': 'logloss'}\n",
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 149.1088\n",
      "Function value obtained: 0.4501\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n",
      "17:30:40 , Params {'learning_rate': 0.01180690886615515, 'n_estimators': 882, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.32265530529279973, 'subsample': 0.7361320112754969, 'colsample_bytree': 0.9061531632988676, 'lambda': 0.9038700038788012, 'alpha': 0.20840685467167264, 'eval_metric': 'logloss'}\n",
      "Iteration No: 57 ended. Search finished for the next optimal point.\n",
      "Time taken: 356.6059\n",
      "Function value obtained: 0.4440\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 58 started. Searching for the next optimal point.\n",
      "17:36:36 , Params {'learning_rate': 0.011739414090403069, 'n_estimators': 357, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.02102349156710726, 'subsample': 0.8554611979436612, 'colsample_bytree': 0.8054200114400254, 'lambda': 0.6950145275653179, 'alpha': 0.2149877995569936, 'eval_metric': 'logloss'}\n",
      "Iteration No: 58 ended. Search finished for the next optimal point.\n",
      "Time taken: 127.6622\n",
      "Function value obtained: 0.4493\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 59 started. Searching for the next optimal point.\n",
      "17:38:44 , Params {'learning_rate': 0.010453807545749054, 'n_estimators': 308, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.17444909578318588, 'subsample': 0.6560626711670331, 'colsample_bytree': 0.837643887167826, 'lambda': 0.7929809973940612, 'alpha': 0.17791763750202785, 'eval_metric': 'logloss'}\n",
      "Iteration No: 59 ended. Search finished for the next optimal point.\n",
      "Time taken: 123.2200\n",
      "Function value obtained: 0.4525\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 60 started. Searching for the next optimal point.\n",
      "17:40:47 , Params {'learning_rate': 0.028194230817481264, 'n_estimators': 303, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.07020410179330418, 'subsample': 0.7191287365001696, 'colsample_bytree': 0.9064569530236782, 'lambda': 0.8948081652957511, 'alpha': 0.18689223258796897, 'eval_metric': 'logloss'}\n",
      "Iteration No: 60 ended. Search finished for the next optimal point.\n",
      "Time taken: 126.1661\n",
      "Function value obtained: 0.4447\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 61 started. Searching for the next optimal point.\n",
      "17:42:53 , Params {'learning_rate': 0.010017481692782, 'n_estimators': 306, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.4988522126410952, 'subsample': 0.6290985717832165, 'colsample_bytree': 0.8873693299877901, 'lambda': 0.7666031968751753, 'alpha': 0.2582079512824734, 'eval_metric': 'logloss'}\n",
      "Iteration No: 61 ended. Search finished for the next optimal point.\n",
      "Time taken: 130.6266\n",
      "Function value obtained: 0.4532\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 62 started. Searching for the next optimal point.\n",
      "17:45:04 , Params {'learning_rate': 0.010402968114427168, 'n_estimators': 302, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.12889999881128175, 'subsample': 0.9411359950207752, 'colsample_bytree': 0.9765481449409755, 'lambda': 0.7379138265878289, 'alpha': 0.17686790761815394, 'eval_metric': 'logloss'}\n",
      "Iteration No: 62 ended. Search finished for the next optimal point.\n",
      "Time taken: 121.5365\n",
      "Function value obtained: 0.4531\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 63 started. Searching for the next optimal point.\n",
      "17:47:06 , Params {'learning_rate': 0.010489677705752376, 'n_estimators': 309, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.26859812719811277, 'subsample': 0.5505952519904026, 'colsample_bytree': 0.997760724148216, 'lambda': 0.7725700671456237, 'alpha': 0.42948978401559806, 'eval_metric': 'logloss'}\n",
      "Iteration No: 63 ended. Search finished for the next optimal point.\n",
      "Time taken: 147.6955\n",
      "Function value obtained: 0.4523\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 64 started. Searching for the next optimal point.\n",
      "17:49:33 , Params {'learning_rate': 0.010323250569035759, 'n_estimators': 882, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.23947696848681693, 'subsample': 0.9896883084928748, 'colsample_bytree': 0.906501232440123, 'lambda': 0.9646270346944035, 'alpha': 0.38714992109396806, 'eval_metric': 'logloss'}\n",
      "Iteration No: 64 ended. Search finished for the next optimal point.\n",
      "Time taken: 319.6821\n",
      "Function value obtained: 0.4447\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 65 started. Searching for the next optimal point.\n",
      "17:54:53 , Params {'learning_rate': 0.03846456690019029, 'n_estimators': 580, 'min_child_weight': 8, 'max_depth': 9, 'gamma': 0.19591768602605958, 'subsample': 0.5001098055099563, 'colsample_bytree': 0.9942481028825481, 'lambda': 0.7727896257424588, 'alpha': 0.1389799102992955, 'eval_metric': 'logloss'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 65 ended. Search finished for the next optimal point.\n",
      "Time taken: 767.2642\n",
      "Function value obtained: 0.4394\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 66 started. Searching for the next optimal point.\n",
      "18:07:40 , Params {'learning_rate': 0.011681769620496461, 'n_estimators': 305, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.45783509869204203, 'subsample': 0.533002772762959, 'colsample_bytree': 0.8119252909798433, 'lambda': 0.7394642188551581, 'alpha': 0.26759006706680005, 'eval_metric': 'logloss'}\n",
      "Iteration No: 66 ended. Search finished for the next optimal point.\n",
      "Time taken: 214.3905\n",
      "Function value obtained: 0.4510\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 67 started. Searching for the next optimal point.\n",
      "18:11:15 , Params {'learning_rate': 0.03437350012644514, 'n_estimators': 303, 'min_child_weight': 7, 'max_depth': 9, 'gamma': 0.3311406707752367, 'subsample': 0.5766936808669674, 'colsample_bytree': 0.8416496957198666, 'lambda': 0.7631865709660455, 'alpha': 0.06278871097748391, 'eval_metric': 'logloss'}\n",
      "Iteration No: 67 ended. Search finished for the next optimal point.\n",
      "Time taken: 477.9404\n",
      "Function value obtained: 0.4401\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 68 started. Searching for the next optimal point.\n",
      "18:19:13 , Params {'learning_rate': 0.05750601045563229, 'n_estimators': 665, 'min_child_weight': 7, 'max_depth': 8, 'gamma': 0.04339613258732262, 'subsample': 0.5005724270668751, 'colsample_bytree': 0.9250413764940653, 'lambda': 0.6833371555136817, 'alpha': 0.20479220982203938, 'eval_metric': 'logloss'}\n",
      "Iteration No: 68 ended. Search finished for the next optimal point.\n",
      "Time taken: 954.9663\n",
      "Function value obtained: 0.4402\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 69 started. Searching for the next optimal point.\n",
      "18:35:08 , Params {'learning_rate': 0.011082236984376877, 'n_estimators': 311, 'min_child_weight': 7, 'max_depth': 4, 'gamma': 0.48875404079777107, 'subsample': 0.5431794620345705, 'colsample_bytree': 0.9068570873798525, 'lambda': 0.8357203563889184, 'alpha': 0.4864843625671743, 'eval_metric': 'logloss'}\n",
      "Iteration No: 69 ended. Search finished for the next optimal point.\n",
      "Time taken: 136.4904\n",
      "Function value obtained: 0.4514\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 70 started. Searching for the next optimal point.\n",
      "18:37:24 , Params {'learning_rate': 0.010048069359668864, 'n_estimators': 303, 'min_child_weight': 6, 'max_depth': 6, 'gamma': 0.38590713921329883, 'subsample': 0.9137746353047969, 'colsample_bytree': 0.8416883019305744, 'lambda': 0.7693747227465075, 'alpha': 0.2758432283414121, 'eval_metric': 'logloss'}\n",
      "Iteration No: 70 ended. Search finished for the next optimal point.\n",
      "Time taken: 159.6761\n",
      "Function value obtained: 0.4494\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 71 started. Searching for the next optimal point.\n",
      "18:40:04 , Params {'learning_rate': 0.011125300623688446, 'n_estimators': 315, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.045667526923069586, 'subsample': 0.7573014877916887, 'colsample_bytree': 0.9397980554658648, 'lambda': 0.8336932782202076, 'alpha': 0.09785830893822509, 'eval_metric': 'logloss'}\n",
      "Iteration No: 71 ended. Search finished for the next optimal point.\n",
      "Time taken: 131.9840\n",
      "Function value obtained: 0.4513\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 72 started. Searching for the next optimal point.\n",
      "18:42:16 , Params {'learning_rate': 0.0694948847263618, 'n_estimators': 762, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.01086465040322321, 'subsample': 0.7058988370404289, 'colsample_bytree': 0.9353466184968896, 'lambda': 0.6240558706491551, 'alpha': 0.2678684426154774, 'eval_metric': 'logloss'}\n",
      "Iteration No: 72 ended. Search finished for the next optimal point.\n",
      "Time taken: 317.8870\n",
      "Function value obtained: 0.4397\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 73 started. Searching for the next optimal point.\n",
      "18:47:34 , Params {'learning_rate': 0.010325067041456724, 'n_estimators': 307, 'min_child_weight': 7, 'max_depth': 4, 'gamma': 0.372368472274336, 'subsample': 0.6010226581846548, 'colsample_bytree': 0.9803961484577516, 'lambda': 0.9228468649730648, 'alpha': 0.3233989386488278, 'eval_metric': 'logloss'}\n",
      "Iteration No: 73 ended. Search finished for the next optimal point.\n",
      "Time taken: 142.7354\n",
      "Function value obtained: 0.4528\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 74 started. Searching for the next optimal point.\n",
      "18:49:56 , Params {'learning_rate': 0.06967686947461911, 'n_estimators': 396, 'min_child_weight': 7, 'max_depth': 6, 'gamma': 0.0026856245000175254, 'subsample': 0.7920732251523896, 'colsample_bytree': 0.9941771900525753, 'lambda': 0.7490606637909147, 'alpha': 0.04888532074031206, 'eval_metric': 'logloss'}\n",
      "Iteration No: 74 ended. Search finished for the next optimal point.\n",
      "Time taken: 251.3981\n",
      "Function value obtained: 0.4398\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 75 started. Searching for the next optimal point.\n",
      "18:54:08 , Params {'learning_rate': 0.01927452255567793, 'n_estimators': 307, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.21414917115584675, 'subsample': 0.7651023056594408, 'colsample_bytree': 0.848546360749342, 'lambda': 0.9048540140043428, 'alpha': 0.21478759397672448, 'eval_metric': 'logloss'}\n",
      "Iteration No: 75 ended. Search finished for the next optimal point.\n",
      "Time taken: 118.5538\n",
      "Function value obtained: 0.4467\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 76 started. Searching for the next optimal point.\n",
      "18:56:06 , Params {'learning_rate': 0.010551497737679771, 'n_estimators': 305, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.27866088140017187, 'subsample': 0.7008400427301447, 'colsample_bytree': 0.9827353164466237, 'lambda': 0.8284756159775535, 'alpha': 0.12920415163695972, 'eval_metric': 'logloss'}\n",
      "Iteration No: 76 ended. Search finished for the next optimal point.\n",
      "Time taken: 136.6467\n",
      "Function value obtained: 0.4526\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 77 started. Searching for the next optimal point.\n",
      "18:58:23 , Params {'learning_rate': 0.06790693472902727, 'n_estimators': 320, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.42002463087827596, 'subsample': 0.9022975834545308, 'colsample_bytree': 0.9954049496644708, 'lambda': 0.8401575272458387, 'alpha': 0.17526568252908534, 'eval_metric': 'logloss'}\n",
      "Iteration No: 77 ended. Search finished for the next optimal point.\n",
      "Time taken: 131.6143\n",
      "Function value obtained: 0.4419\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 78 started. Searching for the next optimal point.\n",
      "19:00:35 , Params {'learning_rate': 0.010394516440557715, 'n_estimators': 301, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.024426681192493645, 'subsample': 0.9956892181484698, 'colsample_bytree': 0.9404327000523407, 'lambda': 0.779914203364449, 'alpha': 0.04576174689492219, 'eval_metric': 'logloss'}\n",
      "Iteration No: 78 ended. Search finished for the next optimal point.\n",
      "Time taken: 115.3706\n",
      "Function value obtained: 0.4532\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 79 started. Searching for the next optimal point.\n",
      "19:02:30 , Params {'learning_rate': 0.06548653773843108, 'n_estimators': 363, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.18157256203477065, 'subsample': 0.5194432987647924, 'colsample_bytree': 0.9382288032753053, 'lambda': 0.7984180822357272, 'alpha': 0.12236207769247062, 'eval_metric': 'logloss'}\n",
      "Iteration No: 79 ended. Search finished for the next optimal point.\n",
      "Time taken: 163.7938\n",
      "Function value obtained: 0.4412\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 80 started. Searching for the next optimal point.\n",
      "19:05:14 , Params {'learning_rate': 0.035440100430481736, 'n_estimators': 308, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.1387669885151588, 'subsample': 0.7381417150753489, 'colsample_bytree': 0.8655810981702761, 'lambda': 0.7164668632744128, 'alpha': 0.4130951150023314, 'eval_metric': 'logloss'}\n",
      "Iteration No: 80 ended. Search finished for the next optimal point.\n",
      "Time taken: 273.2441\n",
      "Function value obtained: 0.4401\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 81 started. Searching for the next optimal point.\n",
      "19:09:47 , Params {'learning_rate': 0.047899980623763015, 'n_estimators': 302, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.18163808387951982, 'subsample': 0.889749221167651, 'colsample_bytree': 0.8123420450090653, 'lambda': 0.6490682110624004, 'alpha': 0.19222741322522574, 'eval_metric': 'logloss'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 81 ended. Search finished for the next optimal point.\n",
      "Time taken: 236.4699\n",
      "Function value obtained: 0.4398\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 82 started. Searching for the next optimal point.\n",
      "19:13:43 , Params {'learning_rate': 0.011081065364768898, 'n_estimators': 303, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.16335442463137886, 'subsample': 0.6374377997463996, 'colsample_bytree': 0.874295048448734, 'lambda': 0.6637151895474483, 'alpha': 0.11062419682366045, 'eval_metric': 'logloss'}\n",
      "Iteration No: 82 ended. Search finished for the next optimal point.\n",
      "Time taken: 128.8081\n",
      "Function value obtained: 0.4519\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 83 started. Searching for the next optimal point.\n",
      "19:15:52 , Params {'learning_rate': 0.010055567992499148, 'n_estimators': 304, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.4351900796272296, 'subsample': 0.765663871427064, 'colsample_bytree': 0.8492990473275075, 'lambda': 0.8247620486062637, 'alpha': 0.1355609923230687, 'eval_metric': 'logloss'}\n",
      "Iteration No: 83 ended. Search finished for the next optimal point.\n",
      "Time taken: 119.8388\n",
      "Function value obtained: 0.4534\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 84 started. Searching for the next optimal point.\n",
      "19:17:52 , Params {'learning_rate': 0.011044705586964507, 'n_estimators': 310, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.2542969235893573, 'subsample': 0.8730338931740638, 'colsample_bytree': 0.9436564830981456, 'lambda': 0.6087669830560364, 'alpha': 0.21811114139514065, 'eval_metric': 'logloss'}\n",
      "Iteration No: 84 ended. Search finished for the next optimal point.\n",
      "Time taken: 129.7808\n",
      "Function value obtained: 0.4517\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 85 started. Searching for the next optimal point.\n",
      "19:20:02 , Params {'learning_rate': 0.011260585884199384, 'n_estimators': 887, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.4845231696791614, 'subsample': 0.619176776881009, 'colsample_bytree': 0.9416613451419863, 'lambda': 0.9606986244755209, 'alpha': 0.4654315571009724, 'eval_metric': 'logloss'}\n",
      "Iteration No: 85 ended. Search finished for the next optimal point.\n",
      "Time taken: 356.0084\n",
      "Function value obtained: 0.4441\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 86 started. Searching for the next optimal point.\n",
      "19:25:58 , Params {'learning_rate': 0.010888618923562637, 'n_estimators': 890, 'min_child_weight': 8, 'max_depth': 9, 'gamma': 0.06068640957007322, 'subsample': 0.7728404536569539, 'colsample_bytree': 0.9310855439964763, 'lambda': 0.9210089315844842, 'alpha': 0.35768499068454823, 'eval_metric': 'logloss'}\n",
      "Iteration No: 86 ended. Search finished for the next optimal point.\n",
      "Time taken: 698.8641\n",
      "Function value obtained: 0.4401\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 87 started. Searching for the next optimal point.\n",
      "19:37:37 , Params {'learning_rate': 0.010002575763217676, 'n_estimators': 321, 'min_child_weight': 6, 'max_depth': 9, 'gamma': 0.1561139006937917, 'subsample': 0.718148164600102, 'colsample_bytree': 0.8388252647930056, 'lambda': 0.8031470872310942, 'alpha': 0.08344300134444539, 'eval_metric': 'logloss'}\n",
      "Iteration No: 87 ended. Search finished for the next optimal point.\n",
      "Time taken: 244.6436\n",
      "Function value obtained: 0.4454\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 88 started. Searching for the next optimal point.\n",
      "19:41:41 , Params {'learning_rate': 0.020268749399776333, 'n_estimators': 300, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.3254400583592996, 'subsample': 0.9145984587804517, 'colsample_bytree': 0.958603742938714, 'lambda': 0.8615781651039457, 'alpha': 0.15710006547352426, 'eval_metric': 'logloss'}\n",
      "Iteration No: 88 ended. Search finished for the next optimal point.\n",
      "Time taken: 235.1336\n",
      "Function value obtained: 0.4417\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 89 started. Searching for the next optimal point.\n",
      "19:45:37 , Params {'learning_rate': 0.06952907877401458, 'n_estimators': 388, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.10131598310213005, 'subsample': 0.804907239563246, 'colsample_bytree': 0.877862944547848, 'lambda': 0.8574842169589474, 'alpha': 0.23071384802681938, 'eval_metric': 'logloss'}\n",
      "Iteration No: 89 ended. Search finished for the next optimal point.\n",
      "Time taken: 133.5403\n",
      "Function value obtained: 0.4412\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 90 started. Searching for the next optimal point.\n",
      "19:47:50 , Params {'learning_rate': 0.010870681931781435, 'n_estimators': 890, 'min_child_weight': 8, 'max_depth': 9, 'gamma': 0.33610223745974055, 'subsample': 0.9277036087909376, 'colsample_bytree': 0.9756096981772047, 'lambda': 0.9648823521225767, 'alpha': 0.06039182512235826, 'eval_metric': 'logloss'}\n",
      "Iteration No: 90 ended. Search finished for the next optimal point.\n",
      "Time taken: 706.3357\n",
      "Function value obtained: 0.4404\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 91 started. Searching for the next optimal point.\n",
      "19:59:36 , Params {'learning_rate': 0.010815774006916537, 'n_estimators': 892, 'min_child_weight': 7, 'max_depth': 8, 'gamma': 0.07017887568834615, 'subsample': 0.6359783968179812, 'colsample_bytree': 0.9396060471010677, 'lambda': 0.6810265234917149, 'alpha': 0.2767439433623608, 'eval_metric': 'logloss'}\n",
      "Iteration No: 91 ended. Search finished for the next optimal point.\n",
      "Time taken: 697.3357\n",
      "Function value obtained: 0.4404\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 92 started. Searching for the next optimal point.\n",
      "20:11:14 , Params {'learning_rate': 0.010283612515084075, 'n_estimators': 300, 'min_child_weight': 6, 'max_depth': 9, 'gamma': 0.4694690817392694, 'subsample': 0.5027534851209243, 'colsample_bytree': 0.8831920500915207, 'lambda': 0.6414547754334763, 'alpha': 0.4661499158032701, 'eval_metric': 'logloss'}\n",
      "Iteration No: 92 ended. Search finished for the next optimal point.\n",
      "Time taken: 264.5934\n",
      "Function value obtained: 0.4458\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 93 started. Searching for the next optimal point.\n",
      "20:15:38 , Params {'learning_rate': 0.01204063227121873, 'n_estimators': 897, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.4816631199313723, 'subsample': 0.7056873245822044, 'colsample_bytree': 0.8724833392619658, 'lambda': 0.7322529406439695, 'alpha': 0.29347198058451246, 'eval_metric': 'logloss'}\n",
      "Iteration No: 93 ended. Search finished for the next optimal point.\n",
      "Time taken: 319.8059\n",
      "Function value obtained: 0.4439\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 94 started. Searching for the next optimal point.\n",
      "20:20:58 , Params {'learning_rate': 0.010738761741446166, 'n_estimators': 315, 'min_child_weight': 7, 'max_depth': 4, 'gamma': 0.12161122355168161, 'subsample': 0.8088182107505996, 'colsample_bytree': 0.8945577816112749, 'lambda': 0.9943425624954332, 'alpha': 0.15831311907423193, 'eval_metric': 'logloss'}\n",
      "Iteration No: 94 ended. Search finished for the next optimal point.\n",
      "Time taken: 112.5112\n",
      "Function value obtained: 0.4519\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 95 started. Searching for the next optimal point.\n",
      "20:22:51 , Params {'learning_rate': 0.0401231109004541, 'n_estimators': 327, 'min_child_weight': 8, 'max_depth': 7, 'gamma': 0.02556070671968303, 'subsample': 0.9962076061894516, 'colsample_bytree': 0.8855279524401558, 'lambda': 0.9384078896613461, 'alpha': 0.2838382856360286, 'eval_metric': 'logloss'}\n",
      "Iteration No: 95 ended. Search finished for the next optimal point.\n",
      "Time taken: 179.1861\n",
      "Function value obtained: 0.4409\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 96 started. Searching for the next optimal point.\n",
      "20:25:50 , Params {'learning_rate': 0.06749460843574823, 'n_estimators': 789, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.17161834749121715, 'subsample': 0.5735451950394593, 'colsample_bytree': 0.9835562528010863, 'lambda': 0.700843136516993, 'alpha': 0.10457867776333571, 'eval_metric': 'logloss'}\n",
      "Iteration No: 96 ended. Search finished for the next optimal point.\n",
      "Time taken: 326.2488\n",
      "Function value obtained: 0.4397\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 97 started. Searching for the next optimal point.\n",
      "20:31:16 , Params {'learning_rate': 0.06780133793616437, 'n_estimators': 713, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.03167697195395736, 'subsample': 0.5323474153127898, 'colsample_bytree': 0.9917948022684144, 'lambda': 0.6244308091984212, 'alpha': 0.201374482009624, 'eval_metric': 'logloss'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 97 ended. Search finished for the next optimal point.\n",
      "Time taken: 300.5500\n",
      "Function value obtained: 0.4398\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 98 started. Searching for the next optimal point.\n",
      "20:36:17 , Params {'learning_rate': 0.011276332245560298, 'n_estimators': 895, 'min_child_weight': 6, 'max_depth': 7, 'gamma': 0.033197985061516895, 'subsample': 0.800254575753599, 'colsample_bytree': 0.9276324414605639, 'lambda': 0.8051247531273129, 'alpha': 0.340061090102046, 'eval_metric': 'logloss'}\n",
      "Iteration No: 98 ended. Search finished for the next optimal point.\n",
      "Time taken: 554.7041\n",
      "Function value obtained: 0.4411\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 99 started. Searching for the next optimal point.\n",
      "20:45:31 , Params {'learning_rate': 0.06902094946530948, 'n_estimators': 419, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.1131154073303828, 'subsample': 0.5217723390632322, 'colsample_bytree': 0.9083082929197663, 'lambda': 0.6204962574338669, 'alpha': 0.3506191309321791, 'eval_metric': 'logloss'}\n",
      "Iteration No: 99 ended. Search finished for the next optimal point.\n",
      "Time taken: 164.7714\n",
      "Function value obtained: 0.4409\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 100 started. Searching for the next optimal point.\n",
      "20:48:16 , Params {'learning_rate': 0.010784741653555623, 'n_estimators': 898, 'min_child_weight': 6, 'max_depth': 7, 'gamma': 0.17666208049004753, 'subsample': 0.5297926878927838, 'colsample_bytree': 0.8376905621678027, 'lambda': 0.9342732190622024, 'alpha': 0.18872129132954307, 'eval_metric': 'logloss'}\n",
      "Iteration No: 100 ended. Search finished for the next optimal point.\n",
      "Time taken: 651.4838\n",
      "Function value obtained: 0.4410\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 101 started. Searching for the next optimal point.\n",
      "20:59:08 , Params {'learning_rate': 0.010894287399946037, 'n_estimators': 890, 'min_child_weight': 8, 'max_depth': 9, 'gamma': 0.13526940121970119, 'subsample': 0.9097679944208267, 'colsample_bytree': 0.8323258192790934, 'lambda': 0.6003939176986945, 'alpha': 0.35085098752953836, 'eval_metric': 'logloss'}\n",
      "Iteration No: 101 ended. Search finished for the next optimal point.\n",
      "Time taken: 712.7195\n",
      "Function value obtained: 0.4402\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 102 started. Searching for the next optimal point.\n",
      "21:11:00 , Params {'learning_rate': 0.010557959536950674, 'n_estimators': 303, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.09751253845340654, 'subsample': 0.6515582522064995, 'colsample_bytree': 0.9836858088310778, 'lambda': 0.6297246583930652, 'alpha': 0.01664744073175584, 'eval_metric': 'logloss'}\n",
      "Iteration No: 102 ended. Search finished for the next optimal point.\n",
      "Time taken: 138.1430\n",
      "Function value obtained: 0.4526\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 103 started. Searching for the next optimal point.\n",
      "21:13:18 , Params {'learning_rate': 0.03091331043060358, 'n_estimators': 314, 'min_child_weight': 9, 'max_depth': 7, 'gamma': 0.3522797913515068, 'subsample': 0.7594851091168648, 'colsample_bytree': 0.9708961094876429, 'lambda': 0.6099263487162173, 'alpha': 0.47388108796601336, 'eval_metric': 'logloss'}\n",
      "Iteration No: 103 ended. Search finished for the next optimal point.\n",
      "Time taken: 232.6697\n",
      "Function value obtained: 0.4412\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 104 started. Searching for the next optimal point.\n",
      "21:17:11 , Params {'learning_rate': 0.06648288406718775, 'n_estimators': 354, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.4207238452186802, 'subsample': 0.8364515168130822, 'colsample_bytree': 0.9319283797243878, 'lambda': 0.9546748960727177, 'alpha': 0.03238926901855877, 'eval_metric': 'logloss'}\n",
      "Iteration No: 104 ended. Search finished for the next optimal point.\n",
      "Time taken: 147.1773\n",
      "Function value obtained: 0.4416\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 105 started. Searching for the next optimal point.\n",
      "21:19:38 , Params {'learning_rate': 0.010052916774779073, 'n_estimators': 900, 'min_child_weight': 8, 'max_depth': 9, 'gamma': 0.28484426039221067, 'subsample': 0.6952950279326241, 'colsample_bytree': 0.9659431166544094, 'lambda': 0.9983923841977722, 'alpha': 0.0805767866704752, 'eval_metric': 'logloss'}\n",
      "Iteration No: 105 ended. Search finished for the next optimal point.\n",
      "Time taken: 1566.6716\n",
      "Function value obtained: 0.4402\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 106 started. Searching for the next optimal point.\n",
      "21:45:45 , Params {'learning_rate': 0.010538629585849103, 'n_estimators': 891, 'min_child_weight': 6, 'max_depth': 9, 'gamma': 0.005899973538228078, 'subsample': 0.8370205770885155, 'colsample_bytree': 0.8280132704387392, 'lambda': 0.6848660263711512, 'alpha': 0.38056798571021483, 'eval_metric': 'logloss'}\n",
      "Iteration No: 106 ended. Search finished for the next optimal point.\n",
      "Time taken: 777.3724\n",
      "Function value obtained: 0.4402\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 107 started. Searching for the next optimal point.\n",
      "21:58:42 , Params {'learning_rate': 0.0451590383651693, 'n_estimators': 319, 'min_child_weight': 8, 'max_depth': 8, 'gamma': 0.2369815862421668, 'subsample': 0.9730386820485342, 'colsample_bytree': 0.8811815573388231, 'lambda': 0.8208008461725232, 'alpha': 0.4871351321584285, 'eval_metric': 'logloss'}\n",
      "Iteration No: 107 ended. Search finished for the next optimal point.\n",
      "Time taken: 241.7346\n",
      "Function value obtained: 0.4402\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 108 started. Searching for the next optimal point.\n",
      "22:02:44 , Params {'learning_rate': 0.010884360457464912, 'n_estimators': 303, 'min_child_weight': 7, 'max_depth': 4, 'gamma': 0.19983408898225408, 'subsample': 0.973801545206006, 'colsample_bytree': 0.8031198423077932, 'lambda': 0.7185343067446847, 'alpha': 0.34937274313026967, 'eval_metric': 'logloss'}\n",
      "Iteration No: 108 ended. Search finished for the next optimal point.\n",
      "Time taken: 107.8191\n",
      "Function value obtained: 0.4523\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 109 started. Searching for the next optimal point.\n",
      "22:04:32 , Params {'learning_rate': 0.06918337680826872, 'n_estimators': 317, 'min_child_weight': 8, 'max_depth': 6, 'gamma': 0.3668279003537745, 'subsample': 0.5300897444956468, 'colsample_bytree': 0.8325692907543868, 'lambda': 0.964466119392296, 'alpha': 0.26889711468667904, 'eval_metric': 'logloss'}\n",
      "Iteration No: 109 ended. Search finished for the next optimal point.\n",
      "Time taken: 200.6176\n",
      "Function value obtained: 0.4401\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 110 started. Searching for the next optimal point.\n",
      "22:07:53 , Params {'learning_rate': 0.010143735694610544, 'n_estimators': 306, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.26276523565909, 'subsample': 0.5266158255241189, 'colsample_bytree': 0.9901847510684569, 'lambda': 0.7109833543875124, 'alpha': 0.17875110244496387, 'eval_metric': 'logloss'}\n",
      "Iteration No: 110 ended. Search finished for the next optimal point.\n",
      "Time taken: 153.7996\n",
      "Function value obtained: 0.4530\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 111 started. Searching for the next optimal point.\n",
      "22:10:26 , Params {'learning_rate': 0.011014023991120479, 'n_estimators': 894, 'min_child_weight': 8, 'max_depth': 8, 'gamma': 0.058356703811298885, 'subsample': 0.5038672588202548, 'colsample_bytree': 0.9896624768681891, 'lambda': 0.6096825674940688, 'alpha': 0.18103765210239123, 'eval_metric': 'logloss'}\n",
      "Iteration No: 111 ended. Search finished for the next optimal point.\n",
      "Time taken: 1017.2609\n",
      "Function value obtained: 0.4403\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 112 started. Searching for the next optimal point.\n",
      "22:27:24 , Params {'learning_rate': 0.010280583593662178, 'n_estimators': 302, 'min_child_weight': 7, 'max_depth': 4, 'gamma': 0.11683914968206341, 'subsample': 0.5256936970187299, 'colsample_bytree': 0.9283033585416554, 'lambda': 0.7843616601409023, 'alpha': 0.4052150868901359, 'eval_metric': 'logloss'}\n",
      "Iteration No: 112 ended. Search finished for the next optimal point.\n",
      "Time taken: 238.3310\n",
      "Function value obtained: 0.4530\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 113 started. Searching for the next optimal point.\n",
      "22:31:22 , Params {'learning_rate': 0.011504482609813373, 'n_estimators': 303, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.20074734232995162, 'subsample': 0.6839024885222627, 'colsample_bytree': 0.8172397408525495, 'lambda': 0.9470770203480656, 'alpha': 0.131874521232317, 'eval_metric': 'logloss'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 113 ended. Search finished for the next optimal point.\n",
      "Time taken: 205.5381\n",
      "Function value obtained: 0.4514\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 114 started. Searching for the next optimal point.\n",
      "22:34:47 , Params {'learning_rate': 0.06796107003152577, 'n_estimators': 314, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.009487630321292963, 'subsample': 0.7964240407381178, 'colsample_bytree': 0.856162443308825, 'lambda': 0.9993689521383164, 'alpha': 0.08996841618491287, 'eval_metric': 'logloss'}\n",
      "Iteration No: 114 ended. Search finished for the next optimal point.\n",
      "Time taken: 210.1609\n",
      "Function value obtained: 0.4419\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 115 started. Searching for the next optimal point.\n",
      "22:38:18 , Params {'learning_rate': 0.010040633899231514, 'n_estimators': 304, 'min_child_weight': 6, 'max_depth': 9, 'gamma': 0.35604869921811, 'subsample': 0.6612108709644472, 'colsample_bytree': 0.9733446398638465, 'lambda': 0.6061571079984339, 'alpha': 0.44518013259479555, 'eval_metric': 'logloss'}\n",
      "Iteration No: 115 ended. Search finished for the next optimal point.\n",
      "Time taken: 444.1784\n",
      "Function value obtained: 0.4460\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 116 started. Searching for the next optimal point.\n",
      "22:45:42 , Params {'learning_rate': 0.010229891759649872, 'n_estimators': 310, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.45381839763281495, 'subsample': 0.6837576128760537, 'colsample_bytree': 0.9342280890860706, 'lambda': 0.7020950490568953, 'alpha': 0.16788733283065857, 'eval_metric': 'logloss'}\n",
      "Iteration No: 116 ended. Search finished for the next optimal point.\n",
      "Time taken: 132.8992\n",
      "Function value obtained: 0.4528\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 117 started. Searching for the next optimal point.\n",
      "22:47:55 , Params {'learning_rate': 0.0668002056079255, 'n_estimators': 317, 'min_child_weight': 7, 'max_depth': 4, 'gamma': 0.4829733661091824, 'subsample': 0.5925725711077416, 'colsample_bytree': 0.9114159567078773, 'lambda': 0.9512630344622834, 'alpha': 0.4089019324930273, 'eval_metric': 'logloss'}\n",
      "Iteration No: 117 ended. Search finished for the next optimal point.\n",
      "Time taken: 137.8767\n",
      "Function value obtained: 0.4417\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 118 started. Searching for the next optimal point.\n",
      "22:50:13 , Params {'learning_rate': 0.010259843765421032, 'n_estimators': 305, 'min_child_weight': 8, 'max_depth': 5, 'gamma': 0.000439592540189493, 'subsample': 0.6640511283315192, 'colsample_bytree': 0.9497668832731244, 'lambda': 0.8061200823113079, 'alpha': 0.010467753984814034, 'eval_metric': 'logloss'}\n",
      "Iteration No: 118 ended. Search finished for the next optimal point.\n",
      "Time taken: 165.9348\n",
      "Function value obtained: 0.4506\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 119 started. Searching for the next optimal point.\n",
      "22:52:59 , Params {'learning_rate': 0.017218080150470574, 'n_estimators': 316, 'min_child_weight': 8, 'max_depth': 9, 'gamma': 0.011020533506050591, 'subsample': 0.637878558429052, 'colsample_bytree': 0.8534807683133391, 'lambda': 0.9804018769514784, 'alpha': 0.3336076720421254, 'eval_metric': 'logloss'}\n",
      "Iteration No: 119 ended. Search finished for the next optimal point.\n",
      "Time taken: 292.0116\n",
      "Function value obtained: 0.4418\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 120 started. Searching for the next optimal point.\n",
      "22:57:51 , Params {'learning_rate': 0.050206677374705244, 'n_estimators': 302, 'min_child_weight': 5, 'max_depth': 7, 'gamma': 0.4796613603630204, 'subsample': 0.5633223052769671, 'colsample_bytree': 0.8242464841598384, 'lambda': 0.9559808487276222, 'alpha': 0.364618981462006, 'eval_metric': 'logloss'}\n",
      "Iteration No: 120 ended. Search finished for the next optimal point.\n",
      "Time taken: 211.6790\n",
      "Function value obtained: 0.4401\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 121 started. Searching for the next optimal point.\n",
      "23:01:22 , Params {'learning_rate': 0.010308585491957217, 'n_estimators': 301, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.0001963778684849205, 'subsample': 0.6551862435527294, 'colsample_bytree': 0.820641860173271, 'lambda': 0.8506990692266836, 'alpha': 0.40953642388711664, 'eval_metric': 'logloss'}\n",
      "Iteration No: 121 ended. Search finished for the next optimal point.\n",
      "Time taken: 118.7369\n",
      "Function value obtained: 0.4530\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 122 started. Searching for the next optimal point.\n",
      "23:03:21 , Params {'learning_rate': 0.010504366651895376, 'n_estimators': 896, 'min_child_weight': 8, 'max_depth': 7, 'gamma': 0.11943794993982285, 'subsample': 0.5296680605627763, 'colsample_bytree': 0.8651777026547157, 'lambda': 0.7187553144900458, 'alpha': 0.21906980677578497, 'eval_metric': 'logloss'}\n",
      "Iteration No: 122 ended. Search finished for the next optimal point.\n",
      "Time taken: 643.6820\n",
      "Function value obtained: 0.4411\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 123 started. Searching for the next optimal point.\n",
      "23:14:05 , Params {'learning_rate': 0.010470854201865836, 'n_estimators': 896, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 0.31184759055699024, 'subsample': 0.8624536874503705, 'colsample_bytree': 0.8852059318194498, 'lambda': 0.6671689039827533, 'alpha': 0.2822164665104024, 'eval_metric': 'logloss'}\n",
      "Iteration No: 123 ended. Search finished for the next optimal point.\n",
      "Time taken: 673.8565\n",
      "Function value obtained: 0.4432\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 124 started. Searching for the next optimal point.\n",
      "23:25:19 , Params {'learning_rate': 0.011118758023827046, 'n_estimators': 305, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.2635725046987184, 'subsample': 0.6194789127672812, 'colsample_bytree': 0.9755993273909314, 'lambda': 0.6587508327014224, 'alpha': 0.2960759690001161, 'eval_metric': 'logloss'}\n",
      "Iteration No: 124 ended. Search finished for the next optimal point.\n",
      "Time taken: 243.6703\n",
      "Function value obtained: 0.4518\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 125 started. Searching for the next optimal point.\n",
      "23:29:22 , Params {'learning_rate': 0.06932427634540728, 'n_estimators': 301, 'min_child_weight': 9, 'max_depth': 9, 'gamma': 0.17320033916524794, 'subsample': 0.6574921454323785, 'colsample_bytree': 0.9223139721706095, 'lambda': 0.7681341342770892, 'alpha': 0.15658584953900648, 'eval_metric': 'logloss'}\n",
      "Iteration No: 125 ended. Search finished for the next optimal point.\n",
      "Time taken: 500.5465\n",
      "Function value obtained: 0.4399\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 126 started. Searching for the next optimal point.\n",
      "23:37:43 , Params {'learning_rate': 0.010416957802332394, 'n_estimators': 304, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.4921819664171063, 'subsample': 0.7072256084704505, 'colsample_bytree': 0.8283076561327185, 'lambda': 0.6689972135905887, 'alpha': 0.2703947874338256, 'eval_metric': 'logloss'}\n",
      "Iteration No: 126 ended. Search finished for the next optimal point.\n",
      "Time taken: 227.5986\n",
      "Function value obtained: 0.4456\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 127 started. Searching for the next optimal point.\n",
      "23:41:30 , Params {'learning_rate': 0.06934626166701259, 'n_estimators': 726, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.33393519434053803, 'subsample': 0.5486400507192731, 'colsample_bytree': 0.9914262526737478, 'lambda': 0.7331971256344403, 'alpha': 0.46576717239359944, 'eval_metric': 'logloss'}\n",
      "Iteration No: 127 ended. Search finished for the next optimal point.\n",
      "Time taken: 286.0396\n",
      "Function value obtained: 0.4397\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 128 started. Searching for the next optimal point.\n",
      "23:46:16 , Params {'learning_rate': 0.010612197743699502, 'n_estimators': 307, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.023358931765893435, 'subsample': 0.7982749331736431, 'colsample_bytree': 0.8301117096862498, 'lambda': 0.7580012760626589, 'alpha': 0.4804344685872787, 'eval_metric': 'logloss'}\n",
      "Iteration No: 128 ended. Search finished for the next optimal point.\n",
      "Time taken: 96.6738\n",
      "Function value obtained: 0.4524\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 129 started. Searching for the next optimal point.\n",
      "23:47:53 , Params {'learning_rate': 0.010440407678920573, 'n_estimators': 898, 'min_child_weight': 7, 'max_depth': 4, 'gamma': 0.42386807751836947, 'subsample': 0.5285111943330834, 'colsample_bytree': 0.8435817492336227, 'lambda': 0.8838261340853129, 'alpha': 0.20880214675324577, 'eval_metric': 'logloss'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 129 ended. Search finished for the next optimal point.\n",
      "Time taken: 311.3043\n",
      "Function value obtained: 0.4443\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 130 started. Searching for the next optimal point.\n",
      "23:53:04 , Params {'learning_rate': 0.01033593285693411, 'n_estimators': 304, 'min_child_weight': 8, 'max_depth': 4, 'gamma': 0.22882725481816557, 'subsample': 0.9213872810740582, 'colsample_bytree': 0.9058881191516513, 'lambda': 0.7303846217337924, 'alpha': 0.4107198347806353, 'eval_metric': 'logloss'}\n",
      "Iteration No: 130 ended. Search finished for the next optimal point.\n",
      "Time taken: 96.0185\n",
      "Function value obtained: 0.4530\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 131 started. Searching for the next optimal point.\n",
      "23:54:40 , Params {'learning_rate': 0.012095187185754867, 'n_estimators': 893, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.19425194426422454, 'subsample': 0.9223633539836935, 'colsample_bytree': 0.8447991655740335, 'lambda': 0.8008831295867239, 'alpha': 0.02954498051061317, 'eval_metric': 'logloss'}\n",
      "Iteration No: 131 ended. Search finished for the next optimal point.\n",
      "Time taken: 261.0793\n",
      "Function value obtained: 0.4440\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 132 started. Searching for the next optimal point.\n",
      "23:59:01 , Params {'learning_rate': 0.06951881953794439, 'n_estimators': 304, 'min_child_weight': 6, 'max_depth': 5, 'gamma': 0.09577871203046626, 'subsample': 0.7426710033832822, 'colsample_bytree': 0.9564082723299673, 'lambda': 0.6279974507568268, 'alpha': 0.39792498891206085, 'eval_metric': 'logloss'}\n",
      "Iteration No: 132 ended. Search finished for the next optimal point.\n",
      "Time taken: 133.3183\n",
      "Function value obtained: 0.4408\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 133 started. Searching for the next optimal point.\n",
      "00:01:15 , Params {'learning_rate': 0.011992162937853264, 'n_estimators': 893, 'min_child_weight': 7, 'max_depth': 4, 'gamma': 0.27761437335824524, 'subsample': 0.6320357276764373, 'colsample_bytree': 0.9352901549527146, 'lambda': 0.6817190691633298, 'alpha': 0.03883450876696338, 'eval_metric': 'logloss'}\n",
      "Iteration No: 133 ended. Search finished for the next optimal point.\n",
      "Time taken: 326.8989\n",
      "Function value obtained: 0.4438\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 134 started. Searching for the next optimal point.\n",
      "00:06:42 , Params {'learning_rate': 0.010841711001305558, 'n_estimators': 304, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.4832177603014979, 'subsample': 0.8564157570077602, 'colsample_bytree': 0.9211174124961493, 'lambda': 0.7180434015095098, 'alpha': 0.15819230372255452, 'eval_metric': 'logloss'}\n",
      "Iteration No: 134 ended. Search finished for the next optimal point.\n",
      "Time taken: 99.9981\n",
      "Function value obtained: 0.4523\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 135 started. Searching for the next optimal point.\n",
      "00:08:22 , Params {'learning_rate': 0.06952929828685982, 'n_estimators': 305, 'min_child_weight': 6, 'max_depth': 5, 'gamma': 0.4772054723083294, 'subsample': 0.5101088391118549, 'colsample_bytree': 0.9902091743837116, 'lambda': 0.8457431560809575, 'alpha': 0.06741365947583718, 'eval_metric': 'logloss'}\n",
      "Iteration No: 135 ended. Search finished for the next optimal point.\n",
      "Time taken: 151.6258\n",
      "Function value obtained: 0.4406\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 136 started. Searching for the next optimal point.\n",
      "00:10:53 , Params {'learning_rate': 0.010376394104610824, 'n_estimators': 896, 'min_child_weight': 7, 'max_depth': 9, 'gamma': 0.06001843281273268, 'subsample': 0.5293660301017671, 'colsample_bytree': 0.821217897057002, 'lambda': 0.974509675251782, 'alpha': 0.2104417913637301, 'eval_metric': 'logloss'}\n",
      "Iteration No: 136 ended. Search finished for the next optimal point.\n",
      "Time taken: 672.6288\n",
      "Function value obtained: 0.4400\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 137 started. Searching for the next optimal point.\n",
      "00:22:06 , Params {'learning_rate': 0.010118189351081542, 'n_estimators': 894, 'min_child_weight': 7, 'max_depth': 8, 'gamma': 0.11165639078701581, 'subsample': 0.9767496904040605, 'colsample_bytree': 0.8490131064924774, 'lambda': 0.9804235322071948, 'alpha': 0.12303795545396559, 'eval_metric': 'logloss'}\n",
      "Iteration No: 137 ended. Search finished for the next optimal point.\n",
      "Time taken: 506.0571\n",
      "Function value obtained: 0.4409\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 138 started. Searching for the next optimal point.\n",
      "00:30:32 , Params {'learning_rate': 0.054933145225926995, 'n_estimators': 303, 'min_child_weight': 8, 'max_depth': 8, 'gamma': 0.34858244647546166, 'subsample': 0.6063244711775372, 'colsample_bytree': 0.9994246519696941, 'lambda': 0.7620471792646548, 'alpha': 0.0038113082616664804, 'eval_metric': 'logloss'}\n",
      "Iteration No: 138 ended. Search finished for the next optimal point.\n",
      "Time taken: 234.7093\n",
      "Function value obtained: 0.4399\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 139 started. Searching for the next optimal point.\n",
      "00:34:27 , Params {'learning_rate': 0.01121759400423212, 'n_estimators': 893, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.31678629500551864, 'subsample': 0.6005541218546068, 'colsample_bytree': 0.9204661031764548, 'lambda': 0.6801649121748234, 'alpha': 0.266180137429705, 'eval_metric': 'logloss'}\n",
      "Iteration No: 139 ended. Search finished for the next optimal point.\n",
      "Time taken: 325.9607\n",
      "Function value obtained: 0.4441\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 140 started. Searching for the next optimal point.\n",
      "00:39:53 , Params {'learning_rate': 0.010350164680663966, 'n_estimators': 300, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.06789868551150254, 'subsample': 0.7080326932832661, 'colsample_bytree': 0.8229880931003059, 'lambda': 0.8413934587761382, 'alpha': 0.3136221110654869, 'eval_metric': 'logloss'}\n",
      "Iteration No: 140 ended. Search finished for the next optimal point.\n",
      "Time taken: 98.5102\n",
      "Function value obtained: 0.4531\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 141 started. Searching for the next optimal point.\n",
      "00:41:31 , Params {'learning_rate': 0.010572396102918841, 'n_estimators': 303, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.1424527895345973, 'subsample': 0.5990739510250099, 'colsample_bytree': 0.8169849918309376, 'lambda': 0.9819921073981723, 'alpha': 0.046769996167246815, 'eval_metric': 'logloss'}\n",
      "Iteration No: 141 ended. Search finished for the next optimal point.\n",
      "Time taken: 103.5994\n",
      "Function value obtained: 0.4525\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 142 started. Searching for the next optimal point.\n",
      "00:43:15 , Params {'learning_rate': 0.010394726836970854, 'n_estimators': 301, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.389563066231656, 'subsample': 0.7660562185701218, 'colsample_bytree': 0.8756578823260054, 'lambda': 0.9817677682363232, 'alpha': 0.3696365290504292, 'eval_metric': 'logloss'}\n",
      "Iteration No: 142 ended. Search finished for the next optimal point.\n",
      "Time taken: 100.8866\n",
      "Function value obtained: 0.4530\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 143 started. Searching for the next optimal point.\n",
      "00:44:56 , Params {'learning_rate': 0.010457016656162773, 'n_estimators': 303, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.3361606197277065, 'subsample': 0.9048478948361679, 'colsample_bytree': 0.9934072904997915, 'lambda': 0.6142374604162062, 'alpha': 0.4199266720413934, 'eval_metric': 'logloss'}\n",
      "Iteration No: 143 ended. Search finished for the next optimal point.\n",
      "Time taken: 104.7124\n",
      "Function value obtained: 0.4529\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 144 started. Searching for the next optimal point.\n",
      "00:46:40 , Params {'learning_rate': 0.021636210147919138, 'n_estimators': 527, 'min_child_weight': 9, 'max_depth': 6, 'gamma': 0.22999423256019702, 'subsample': 0.9054710676467446, 'colsample_bytree': 0.877821554570158, 'lambda': 0.8915143268722217, 'alpha': 0.07479019970786412, 'eval_metric': 'logloss'}\n",
      "Iteration No: 144 ended. Search finished for the next optimal point.\n",
      "Time taken: 237.0767\n",
      "Function value obtained: 0.4416\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 145 started. Searching for the next optimal point.\n",
      "00:50:37 , Params {'learning_rate': 0.010719348288263923, 'n_estimators': 516, 'min_child_weight': 6, 'max_depth': 4, 'gamma': 0.42247935287195265, 'subsample': 0.7854200468083785, 'colsample_bytree': 0.9151569515085128, 'lambda': 0.6852843966320878, 'alpha': 0.31004995918425227, 'eval_metric': 'logloss'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 145 ended. Search finished for the next optimal point.\n",
      "Time taken: 174.4518\n",
      "Function value obtained: 0.4471\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 146 started. Searching for the next optimal point.\n",
      "00:53:32 , Params {'learning_rate': 0.06964597016754312, 'n_estimators': 302, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.18482670260824688, 'subsample': 0.9935838838950946, 'colsample_bytree': 0.9244739238598831, 'lambda': 0.6740870860237851, 'alpha': 0.25942909600041997, 'eval_metric': 'logloss'}\n",
      "Iteration No: 146 ended. Search finished for the next optimal point.\n",
      "Time taken: 94.2284\n",
      "Function value obtained: 0.4422\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 147 started. Searching for the next optimal point.\n",
      "00:55:06 , Params {'learning_rate': 0.010043727695454143, 'n_estimators': 900, 'min_child_weight': 5, 'max_depth': 8, 'gamma': 0.041929839612090854, 'subsample': 0.8113515558944862, 'colsample_bytree': 0.9236723432588053, 'lambda': 0.850181041850564, 'alpha': 0.25510954207518566, 'eval_metric': 'logloss'}\n",
      "Iteration No: 147 ended. Search finished for the next optimal point.\n",
      "Time taken: 600.6005\n",
      "Function value obtained: 0.4407\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 148 started. Searching for the next optimal point.\n",
      "01:05:07 , Params {'learning_rate': 0.011882421168101228, 'n_estimators': 887, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.32899330473040667, 'subsample': 0.5376490540374762, 'colsample_bytree': 0.9092764836005336, 'lambda': 0.8418006557309524, 'alpha': 0.48149050406252386, 'eval_metric': 'logloss'}\n",
      "Iteration No: 148 ended. Search finished for the next optimal point.\n",
      "Time taken: 326.1348\n",
      "Function value obtained: 0.4439\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 149 started. Searching for the next optimal point.\n",
      "01:10:33 , Params {'learning_rate': 0.06999636320210119, 'n_estimators': 547, 'min_child_weight': 9, 'max_depth': 6, 'gamma': 0.47300557467939824, 'subsample': 0.840721573913128, 'colsample_bytree': 0.9674318020887959, 'lambda': 0.7082316742921232, 'alpha': 0.45715037256998475, 'eval_metric': 'logloss'}\n",
      "Iteration No: 149 ended. Search finished for the next optimal point.\n",
      "Time taken: 274.9492\n",
      "Function value obtained: 0.4393\n",
      "Current minimum: 0.4390\n",
      "Iteration No: 150 started. Searching for the next optimal point.\n",
      "01:15:08 , Params {'learning_rate': 0.010082195760586386, 'n_estimators': 304, 'min_child_weight': 9, 'max_depth': 4, 'gamma': 0.2519037762180612, 'subsample': 0.8133387236422112, 'colsample_bytree': 0.8104797566426301, 'lambda': 0.7220157642307468, 'alpha': 0.26075235357596416, 'eval_metric': 'logloss'}\n",
      "Iteration No: 150 ended. Search finished for the next optimal point.\n",
      "Time taken: 93.7873\n",
      "Function value obtained: 0.4533\n",
      "Current minimum: 0.4390\n",
      "\n",
      " XGBClassifier , Best Params= [0.037364199053022164, 862, 8, 7, 0.2962072844310213, 0.5232252063599989, 0.9215089703802877, 0.6682096494749166, 0.032525796492639765]  Best Score= 0.438983 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "import warnings\n",
    "np.random.seed(seed)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) # turn off already evaluated errors\n",
    "params={'LogisticRegression': [ \n",
    "                ['l1',],\n",
    "                (1e-1,1e+1,'uniform'),\n",
    "                ],\n",
    "        'GradientBoostingClassifier': [ \n",
    "                (0.04, 0.10, 'uniform'),     # learning rate\n",
    "                (500, 900),                  # n_estimators\n",
    "                (3, 7),                      # max_depth   \n",
    "                (2, 5),                      # min_samples_split \n",
    "                (2, 5),                      # min_samples_leaf \n",
    "                (0, 0.3),                    # min_weight_fraction_leaf \n",
    "                (0.8, 1.0,'uniform'),        # subsample \n",
    "                ('sqrt',),                   # max_features \n",
    "                ],\n",
    "        'XGBClassifier': [\n",
    "                (0.01, 0.07, 'uniform'),    # learning_rate 0.05, 0.3,\n",
    "                (300, 900),                 # n_estimators\n",
    "                (5, 9),                     # min_child_weight \n",
    "                (4, 9),                     # max_depth 3-10\n",
    "                (0, 0.5,   'uniform'),      # gamma 0-0.4\n",
    "                (0.5, 1.0, 'uniform'),      # subsample 0.5 - 0.99\n",
    "                (0.8, 1.0, 'uniform'),      # colsample_bytree 0.5 - 0.99\n",
    "                (0.6, 1.0, 'uniform'),      # reg_lambda\n",
    "                (0.0, 0.5, 'uniform'),      # reg_alpha\n",
    "                ],}\n",
    "\n",
    "model_types = params.keys()\n",
    "model_types = ['XGBClassifier']\n",
    "for model_type in model_types:\n",
    "    cache = {}\n",
    "    space = params[model_type]\n",
    "    result = gbrt_minimize(objective,space,n_random_starts=5, n_calls=150, random_state=seed,verbose=True,n_jobs=-1)\n",
    "    print('\\n', model_type, ', Best Params=', result.x, ' Best Score=', round(result.fun,6),'\\n')\n",
    "    _ = plt.figure(figsize=(15,8))\n",
    "    _ = plot_convergence(result, yscale='log')\n",
    "\n",
    "warnings.filterwarnings(\"default\", category=UserWarning) # turn on already evaluated errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.43898 [0.037364199053022164, 862, 8, 7, 0.2962072844310213, 0.5232252063599989, 0.9215089703802877, 0.6682096494749166, 0.032525796492639765]\n",
      "   0.43902 [0.028171385913113203, 868, 7, 8, 0.1399151764524502, 0.5105537312591736, 0.9717820488325419, 0.7328192598050536, 0.13784916014174478]\n",
      "   0.43935 [0.06999636320210119, 547, 9, 6, 0.47300557467939824, 0.840721573913128, 0.9674318020887959, 0.7082316742921232, 0.45715037256998475]\n",
      "   0.43935 [0.032472407130841756, 570, 7, 8, 0.29842507897324355, 0.7229163764267956, 0.8199949831636006, 0.7836995567863468, 0.16685430556951095]\n",
      "   0.43936 [0.046028228015114137, 889, 8, 7, 0.1778621953347557, 0.6066553844532139, 0.9902486270504814, 0.6512632065360177, 0.48242601373407357]\n",
      "   0.43941 [0.03846456690019029, 580, 8, 9, 0.19591768602605958, 0.5001098055099563, 0.9942481028825481, 0.7727896257424588, 0.1389799102992955]\n",
      "   0.43956 [0.0669331322352, 615, 6, 5, 0.15230688458668537, 0.5488360570031919, 0.9368466053024314, 0.7760609974958406, 0.06101911742238943]\n",
      "   0.43961 [0.04599678042687489, 699, 9, 9, 0.0023991659704465933, 0.5955671287456479, 0.8207942723349781, 0.9871768896830047, 0.23628628194568896]\n",
      "   0.43963 [0.06516297297069994, 645, 9, 7, 0.0063007335564111994, 0.5309961208961936, 0.8526048104183503, 0.7255341053325345, 0.27142825209819643]\n",
      "   0.43966 [0.044676178119060654, 431, 8, 9, 0.25411300494169925, 0.520606743565454, 0.8075511663774058, 0.6598749359933285, 0.08619419661392498]\n",
      "   0.43966 [0.039612794820407124, 817, 5, 9, 0.39114738228789775, 0.5297860772180321, 0.9104091604426923, 0.6518344268507689, 0.025768892816983198]\n",
      "   0.43969 [0.0694948847263618, 762, 6, 4, 0.01086465040322321, 0.7058988370404289, 0.9353466184968896, 0.6240558706491551, 0.2678684426154774]\n",
      "   0.43969 [0.01605752479227608, 884, 9, 9, 0.2718888181990053, 0.9112255371225326, 0.944490606645503, 0.8424692540408656, 0.09455362457032992]\n",
      "    0.4397 [0.06934626166701259, 726, 8, 4, 0.33393519434053803, 0.5486400507192731, 0.9914262526737478, 0.7331971256344403, 0.46576717239359944]\n",
      "   0.43973 [0.056164504748053144, 573, 7, 8, 0.10912753637347425, 0.5025567863832433, 0.8010923735412887, 0.8941923568252677, 0.3091801558645695]\n",
      "   0.43974 [0.06749460843574823, 789, 5, 4, 0.17161834749121715, 0.5735451950394593, 0.9835562528010863, 0.700843136516993, 0.10457867776333571]\n",
      "   0.43977 [0.04292561806613531, 846, 5, 9, 0.3083706706585818, 0.9826626429973844, 0.909811816338645, 0.6848703222450128, 0.01927362866821281]\n",
      "    0.4398 [0.06967686947461911, 396, 7, 6, 0.0026856245000175254, 0.7920732251523896, 0.9941771900525753, 0.7490606637909147, 0.04888532074031206]\n",
      "   0.43981 [0.06780133793616437, 713, 6, 4, 0.03167697195395736, 0.5323474153127898, 0.9917948022684144, 0.6244308091984212, 0.201374482009624]\n",
      "   0.43982 [0.047899980623763015, 302, 9, 9, 0.18163808387951982, 0.889749221167651, 0.8123420450090653, 0.6490682110624004, 0.19222741322522574]\n",
      "   0.43982 [0.04093917933744228, 322, 8, 9, 0.2856210165734401, 0.7159921192464007, 0.9548187778875467, 0.6919138458463175, 0.2871119739755865]\n",
      "   0.43988 [0.06932427634540728, 301, 9, 9, 0.17320033916524794, 0.6574921454323785, 0.9223139721706095, 0.7681341342770892, 0.15658584953900648]\n",
      "   0.43991 [0.04896297447548514, 325, 7, 8, 0.10443018450825717, 0.8760400150422343, 0.8168045778211749, 0.6877658000585349, 0.41768723928412016]\n",
      "   0.43993 [0.054933145225926995, 303, 8, 8, 0.34858244647546166, 0.6063244711775372, 0.9994246519696941, 0.7620471792646548, 0.0038113082616664804]\n",
      "   0.43995 [0.055138584476758026, 300, 9, 9, 0.19503634250455354, 0.9497290150071952, 0.8930959602708497, 0.9372456065892046, 0.49337438441773]\n",
      "   0.43997 [0.010376394104610824, 896, 7, 9, 0.06001843281273268, 0.5293660301017671, 0.821217897057002, 0.974509675251782, 0.2104417913637301]\n",
      "   0.44009 [0.03437350012644514, 303, 7, 9, 0.3311406707752367, 0.5766936808669674, 0.8416496957198666, 0.7631865709660455, 0.06278871097748391]\n",
      "    0.4401 [0.010888618923562637, 890, 8, 9, 0.06068640957007322, 0.7728404536569539, 0.9310855439964763, 0.9210089315844842, 0.35768499068454823]\n",
      "   0.44012 [0.06918337680826872, 317, 8, 6, 0.3668279003537745, 0.5300897444956468, 0.8325692907543868, 0.964466119392296, 0.26889711468667904]\n",
      "   0.44012 [0.035440100430481736, 308, 5, 9, 0.1387669885151588, 0.7381417150753489, 0.8655810981702761, 0.7164668632744128, 0.4130951150023314]\n",
      "   0.44014 [0.050206677374705244, 302, 5, 7, 0.4796613603630204, 0.5633223052769671, 0.8242464841598384, 0.9559808487276222, 0.364618981462006]\n",
      "   0.44015 [0.0451590383651693, 319, 8, 8, 0.2369815862421668, 0.9730386820485342, 0.8811815573388231, 0.8208008461725232, 0.4871351321584285]\n",
      "   0.44017 [0.05750601045563229, 665, 7, 8, 0.04339613258732262, 0.5005724270668751, 0.9250413764940653, 0.6833371555136817, 0.20479220982203938]\n",
      "   0.44022 [0.04460811770349425, 484, 6, 6, 0.05678031431940418, 0.9025631737027734, 0.8191539397196635, 0.9983366759058275, 0.007949527274233483]\n",
      "   0.44022 [0.010894287399946037, 890, 8, 9, 0.13526940121970119, 0.9097679944208267, 0.8323258192790934, 0.6003939176986945, 0.35085098752953836]\n",
      "   0.44023 [0.010538629585849103, 891, 6, 9, 0.005899973538228078, 0.8370205770885155, 0.8280132704387392, 0.6848660263711512, 0.38056798571021483]\n",
      "   0.44024 [0.012597215651329442, 894, 9, 9, 0.22562545007595047, 0.980469149180644, 0.99201041314988, 0.8598063524170247, 0.26781539355673994]\n",
      "   0.44025 [0.010052916774779073, 900, 8, 9, 0.28484426039221067, 0.6952950279326241, 0.9659431166544094, 0.9983923841977722, 0.0805767866704752]\n",
      "   0.44027 [0.06506569609297086, 857, 6, 8, 0.3427445488422126, 0.6506047694323046, 0.8005724711222457, 0.6201824077171363, 0.05586489967522863]\n",
      "    0.4403 [0.04431571441632242, 401, 9, 6, 0.15692041389851438, 0.5164334741686463, 0.9972582207110791, 0.9723560152262072, 0.030022267963875367]\n",
      "    0.4403 [0.05300831019517769, 328, 7, 6, 0.03350989653556547, 0.5640379285681308, 0.9933543806569972, 0.6853984995909982, 0.426180362691161]\n",
      "   0.44034 [0.011014023991120479, 894, 8, 8, 0.058356703811298885, 0.5038672588202548, 0.9896624768681891, 0.6096825674940688, 0.18103765210239123]\n",
      "   0.44036 [0.027311186965507765, 387, 6, 9, 0.4207655950007227, 0.9887195977147702, 0.8324161448557952, 0.8014653874722327, 0.14111255012655474]\n",
      "   0.44037 [0.02242562240602527, 611, 8, 7, 0.4289836598002877, 0.8597177736280333, 0.8935617434562031, 0.9907257637596014, 0.40680527721011045]\n",
      "   0.44037 [0.010870681931781435, 890, 8, 9, 0.33610223745974055, 0.9277036087909376, 0.9756096981772047, 0.9648823521225767, 0.06039182512235826]\n",
      "   0.44039 [0.05658373799746152, 878, 8, 9, 0.49672346609696894, 0.7581717790742497, 0.8000622207685605, 0.7728222560420487, 0.06782754376509705]\n",
      "    0.4404 [0.06837479249334037, 323, 7, 6, 0.4833521884510503, 0.9780440362056955, 0.8152173048456046, 0.7079789283781046, 0.4850318357682773]\n",
      "    0.4404 [0.010815774006916537, 892, 7, 8, 0.07017887568834615, 0.6359783968179812, 0.9396060471010677, 0.6810265234917149, 0.2767439433623608]\n",
      "   0.44063 [0.06952929828685982, 305, 6, 5, 0.4772054723083294, 0.5101088391118549, 0.9902091743837116, 0.8457431560809575, 0.06741365947583718]\n",
      "   0.44074 [0.010043727695454143, 900, 5, 8, 0.041929839612090854, 0.8113515558944862, 0.9236723432588053, 0.850181041850564, 0.25510954207518566]\n",
      "   0.44076 [0.06951881953794439, 304, 6, 5, 0.09577871203046626, 0.7426710033832822, 0.9564082723299673, 0.6279974507568268, 0.39792498891206085]\n",
      "   0.44087 [0.0401231109004541, 327, 8, 7, 0.02556070671968303, 0.9962076061894516, 0.8855279524401558, 0.9384078896613461, 0.2838382856360286]\n",
      "   0.44089 [0.012120666765105741, 897, 7, 7, 0.22273894604479066, 0.8452184065616778, 0.8114203133075448, 0.7702275489177888, 0.4761018897179315]\n",
      "   0.44092 [0.06902094946530948, 419, 6, 4, 0.1131154073303828, 0.5217723390632322, 0.9083082929197663, 0.6204962574338669, 0.3506191309321791]\n",
      "   0.44095 [0.010118189351081542, 894, 7, 8, 0.11165639078701581, 0.9767496904040605, 0.8490131064924774, 0.9804235322071948, 0.12303795545396559]\n",
      "   0.44096 [0.010784741653555623, 898, 6, 7, 0.17666208049004753, 0.5297926878927838, 0.8376905621678027, 0.9342732190622024, 0.18872129132954307]\n",
      "   0.44106 [0.010504366651895376, 896, 8, 7, 0.11943794993982285, 0.5296680605627763, 0.8651777026547157, 0.7187553144900458, 0.21906980677578497]\n",
      "   0.44109 [0.011276332245560298, 895, 6, 7, 0.033197985061516895, 0.800254575753599, 0.9276324414605639, 0.8051247531273129, 0.340061090102046]\n",
      "   0.44117 [0.06952907877401458, 388, 6, 4, 0.10131598310213005, 0.804907239563246, 0.877862944547848, 0.8574842169589474, 0.23071384802681938]\n",
      "   0.44119 [0.06548653773843108, 363, 5, 4, 0.18157256203477065, 0.5194432987647924, 0.9382288032753053, 0.7984180822357272, 0.12236207769247062]\n",
      "   0.44124 [0.03091331043060358, 314, 9, 7, 0.3522797913515068, 0.7594851091168648, 0.9708961094876429, 0.6099263487162173, 0.47388108796601336]\n",
      "   0.44125 [0.011447635017378761, 888, 9, 7, 0.09475914069775696, 0.9580263742454498, 0.8691063237725914, 0.6437489739476847, 0.35882754629602187]\n",
      "    0.4413 [0.04669918962929686, 552, 8, 4, 0.14561457009902098, 0.8059264473611898, 0.8278987721304084, 0.7168578594140873, 0.18318092164684588]\n",
      "   0.44149 [0.015030313147385283, 505, 8, 8, 0.03571057979276016, 0.9666805943084698, 0.873215729623183, 0.7907854309970331, 0.3527001736465057]\n",
      "   0.44156 [0.052959111644286856, 314, 7, 5, 0.00351033101267595, 0.9318356276179142, 0.8127554615115371, 0.6742762570623557, 0.44857411927958074]\n",
      "   0.44157 [0.06648288406718775, 354, 5, 4, 0.4207238452186802, 0.8364515168130822, 0.9319283797243878, 0.9546748960727177, 0.03238926901855877]\n",
      "   0.44165 [0.021636210147919138, 527, 9, 6, 0.22999423256019702, 0.9054710676467446, 0.877821554570158, 0.8915143268722217, 0.07479019970786412]\n",
      "   0.44165 [0.01592949862397164, 414, 8, 8, 0.4722957473311637, 0.667214087138515, 0.8064300549585419, 0.6926276404331178, 0.033448004215282275]\n",
      "   0.44167 [0.020268749399776333, 300, 9, 9, 0.3254400583592996, 0.9145984587804517, 0.958603742938714, 0.8615781651039457, 0.15710006547352426]\n",
      "   0.44173 [0.0668002056079255, 317, 7, 4, 0.4829733661091824, 0.5925725711077416, 0.9114159567078773, 0.9512630344622834, 0.4089019324930273]\n",
      "   0.44185 [0.017218080150470574, 316, 8, 9, 0.011020533506050591, 0.637878558429052, 0.8534807683133391, 0.9804018769514784, 0.3336076720421254]\n",
      "   0.44189 [0.06796107003152577, 314, 9, 4, 0.009487630321292963, 0.7964240407381178, 0.856162443308825, 0.9993689521383164, 0.08996841618491287]\n",
      "   0.44191 [0.06790693472902727, 320, 6, 4, 0.42002463087827596, 0.9022975834545308, 0.9954049496644708, 0.8401575272458387, 0.17526568252908534]\n",
      "   0.44192 [0.010316856528607433, 899, 9, 6, 0.4082820969071005, 0.5724712000915875, 0.8753574733780256, 0.8285218961621803, 0.002874694005715939]\n",
      "   0.44223 [0.06964597016754312, 302, 5, 4, 0.18482670260824688, 0.9935838838950946, 0.9244739238598831, 0.6740870860237851, 0.25942909600041997]\n",
      "   0.44251 [0.013656410074271864, 408, 5, 8, 0.346295839689176, 0.9602235883784526, 0.9601280783254214, 0.9503371117185225, 0.433886818822869]\n",
      "   0.44262 [0.05077970400185275, 305, 6, 4, 0.002884555392416111, 0.6614919144006347, 0.9804679108134416, 0.6713174030040203, 0.43175865542415676]\n",
      "   0.44287 [0.028946695122033135, 501, 9, 4, 0.2772257117739506, 0.7981611101312991, 0.9588188645948623, 0.7640001294451593, 0.06680363445347128]\n",
      "    0.4432 [0.010470854201865836, 896, 5, 5, 0.31184759055699024, 0.8624536874503705, 0.8852059318194498, 0.6671689039827533, 0.2822164665104024]\n",
      "    0.4432 [0.010249778283191506, 873, 6, 5, 0.09688668551831534, 0.7307922007850552, 0.9368728214240245, 0.6737446117174926, 0.2628445552238194]\n",
      "   0.44336 [0.011850726689681167, 784, 8, 5, 0.009295952417744004, 0.9737006429571686, 0.8612760788602299, 0.9684835307246287, 0.2536395771103177]\n",
      "   0.44345 [0.01894747014574777, 659, 9, 4, 0.06461472169531608, 0.8815352902072888, 0.844018332846806, 0.7431802576207611, 0.4983212427774754]\n",
      "   0.44356 [0.013352884549298213, 390, 9, 7, 0.4794205912442671, 0.8965198704117161, 0.9269415523023449, 0.8929965723908371, 0.4576996600504654]\n",
      "   0.44385 [0.011992162937853264, 893, 7, 4, 0.27761437335824524, 0.6320357276764373, 0.9352901549527146, 0.6817190691633298, 0.03883450876696338]\n",
      "   0.44385 [0.01204063227121873, 897, 6, 4, 0.4816631199313723, 0.7056873245822044, 0.8724833392619658, 0.7322529406439695, 0.29347198058451246]\n",
      "   0.44387 [0.011882421168101228, 887, 5, 4, 0.32899330473040667, 0.5376490540374762, 0.9092764836005336, 0.8418006557309524, 0.48149050406252386]\n",
      "   0.44389 [0.018572009075316448, 430, 9, 5, 0.3609993861334124, 0.9692763545078752, 0.8001557531682029, 0.996884623716487, 0.3087407548138583]\n",
      "   0.44401 [0.01180690886615515, 882, 5, 4, 0.32265530529279973, 0.7361320112754969, 0.9061531632988676, 0.9038700038788012, 0.20840685467167264]\n",
      "   0.44405 [0.012095187185754867, 893, 6, 4, 0.19425194426422454, 0.9223633539836935, 0.8447991655740335, 0.8008831295867239, 0.02954498051061317]\n",
      "   0.44406 [0.01121759400423212, 893, 5, 4, 0.31678629500551864, 0.6005541218546068, 0.9204661031764548, 0.6801649121748234, 0.266180137429705]\n",
      "   0.44409 [0.01183149525605268, 594, 9, 5, 0.27721416426605866, 0.5675303006399686, 0.8903036547066469, 0.6371178174495238, 0.16005674348056873]\n",
      "   0.44409 [0.011260585884199384, 887, 9, 4, 0.4845231696791614, 0.619176776881009, 0.9416613451419863, 0.9606986244755209, 0.4654315571009724]\n",
      "    0.4443 [0.011985939362168265, 442, 5, 6, 0.3551130166630681, 0.6764143076154374, 0.8986002234623314, 0.9819184311094402, 0.49647698407838786]\n",
      "    0.4443 [0.010440407678920573, 898, 7, 4, 0.42386807751836947, 0.5285111943330834, 0.8435817492336227, 0.8838261340853129, 0.20880214675324577]\n",
      "   0.44447 [0.010538039492754215, 407, 9, 7, 0.29778173066234825, 0.5069955519333361, 0.865450872649614, 0.6458472846195767, 0.46114751327171816]\n",
      "   0.44447 [0.010823894322126338, 320, 9, 9, 0.49964759922486934, 0.5685789730384845, 0.8366504886589864, 0.880402539006198, 0.35979818988046874]\n",
      "   0.44456 [0.011611729289826145, 309, 9, 9, 0.07141922153314696, 0.9727972382458898, 0.9050270733268829, 0.8058016988432071, 0.3267548951009453]\n",
      "   0.44472 [0.010323250569035759, 882, 6, 4, 0.23947696848681693, 0.9896883084928748, 0.906501232440123, 0.9646270346944035, 0.38714992109396806]\n",
      "   0.44474 [0.028194230817481264, 303, 9, 4, 0.07020410179330418, 0.7191287365001696, 0.9064569530236782, 0.8948081652957511, 0.18689223258796897]\n",
      "   0.44479 [0.011274236113741485, 567, 7, 5, 0.016590131414292556, 0.9434937128507824, 0.8588993609896134, 0.8830036310094921, 0.4634150078137819]\n",
      "   0.44534 [0.012285656902053948, 377, 9, 6, 0.04723163519261454, 0.9700582828702071, 0.869648294544243, 0.8823264882105261, 0.23181440480738824]\n",
      "   0.44541 [0.010002575763217676, 321, 6, 9, 0.1561139006937917, 0.718148164600102, 0.8388252647930056, 0.8031470872310942, 0.08344300134444539]\n",
      "   0.44558 [0.010416957802332394, 304, 5, 9, 0.4921819664171063, 0.7072256084704505, 0.8283076561327185, 0.6689972135905887, 0.2703947874338256]\n",
      "   0.44575 [0.010283612515084075, 300, 6, 9, 0.4694690817392694, 0.5027534851209243, 0.8831920500915207, 0.6414547754334763, 0.4661499158032701]\n",
      "   0.44597 [0.012235763306244773, 548, 9, 4, 0.08081052248990124, 0.8289456494801692, 0.899432004972052, 0.684129536569669, 0.1536097705958532]\n",
      "   0.44598 [0.010040633899231514, 304, 6, 9, 0.35604869921811, 0.6612108709644472, 0.9733446398638465, 0.6061571079984339, 0.44518013259479555]\n",
      "   0.44598 [0.011837819673098274, 349, 9, 6, 0.1445723936516348, 0.697675144175218, 0.9797537373119819, 0.7892299684709281, 0.16930926286284984]\n",
      "   0.44646 [0.011925958532415015, 396, 9, 5, 0.012648565994462572, 0.8493241444594181, 0.9537416611158581, 0.7163978383666009, 0.3436890307893408]\n",
      "   0.44666 [0.01927452255567793, 307, 5, 4, 0.21414917115584675, 0.7651023056594408, 0.848546360749342, 0.9048540140043428, 0.21478759397672448]\n",
      "   0.44668 [0.012091066540569712, 375, 7, 5, 0.2666993227879508, 0.7574769023561233, 0.8647799204181779, 0.848164331205967, 0.4847526179361339]\n",
      "   0.44707 [0.010719348288263923, 516, 6, 4, 0.42247935287195265, 0.7854200468083785, 0.9151569515085128, 0.6852843966320878, 0.31004995918425227]\n",
      "   0.44931 [0.011739414090403069, 357, 9, 4, 0.02102349156710726, 0.8554611979436612, 0.8054200114400254, 0.6950145275653179, 0.2149877995569936]\n",
      "   0.44942 [0.010048069359668864, 303, 6, 6, 0.38590713921329883, 0.9137746353047969, 0.8416883019305744, 0.7693747227465075, 0.2758432283414121]\n",
      "   0.44954 [0.01121002149052374, 362, 8, 4, 0.27446315501464963, 0.6312899358195496, 0.9705858536412381, 0.9536333898329241, 0.06872244780914523]\n",
      "   0.45015 [0.012092520930398875, 316, 9, 4, 0.24955738765932078, 0.5014527481015036, 0.9912249826233258, 0.7435906256138931, 0.45393522200502173]\n",
      "   0.45019 [0.012078439667212542, 322, 9, 4, 0.00960105397410971, 0.9549289343939935, 0.8938698684310473, 0.7027881076312297, 0.4640990226240796]\n",
      "    0.4504 [0.011853543582918255, 320, 5, 4, 0.47124084778874104, 0.837649519884837, 0.8478188860578764, 0.8475645357112885, 0.4689286913406785]\n",
      "   0.45059 [0.010259843765421032, 305, 8, 5, 0.000439592540189493, 0.6640511283315192, 0.9497668832731244, 0.8061200823113079, 0.010467753984814034]\n",
      "   0.45096 [0.011681769620496461, 305, 6, 4, 0.45783509869204203, 0.533002772762959, 0.8119252909798433, 0.7394642188551581, 0.26759006706680005]\n",
      "   0.45131 [0.011125300623688446, 315, 6, 4, 0.045667526923069586, 0.7573014877916887, 0.9397980554658648, 0.8336932782202076, 0.09785830893822509]\n",
      "   0.45139 [0.011504482609813373, 303, 5, 4, 0.20074734232995162, 0.6839024885222627, 0.8172397408525495, 0.9470770203480656, 0.131874521232317]\n",
      "   0.45144 [0.011082236984376877, 311, 7, 4, 0.48875404079777107, 0.5431794620345705, 0.9068570873798525, 0.8357203563889184, 0.4864843625671743]\n",
      "   0.45172 [0.011044705586964507, 310, 8, 4, 0.2542969235893573, 0.8730338931740638, 0.9436564830981456, 0.6087669830560364, 0.21811114139514065]\n",
      "   0.45175 [0.011118758023827046, 305, 9, 4, 0.2635725046987184, 0.6194789127672812, 0.9755993273909314, 0.6587508327014224, 0.2960759690001161]\n",
      "   0.45185 [0.011081065364768898, 303, 8, 4, 0.16335442463137886, 0.6374377997463996, 0.874295048448734, 0.6637151895474483, 0.11062419682366045]\n",
      "   0.45185 [0.010738761741446166, 315, 7, 4, 0.12161122355168161, 0.8088182107505996, 0.8945577816112749, 0.9943425624954332, 0.15831311907423193]\n",
      "   0.45221 [0.01098780294469218, 302, 8, 4, 0.4052350289896849, 0.9055240266065474, 0.9322197565231404, 0.995506990227317, 0.4819596311649616]\n",
      "   0.45227 [0.010884360457464912, 303, 7, 4, 0.19983408898225408, 0.973801545206006, 0.8031198423077932, 0.7185343067446847, 0.34937274313026967]\n",
      "   0.45228 [0.010841711001305558, 304, 6, 4, 0.4832177603014979, 0.8564157570077602, 0.9211174124961493, 0.7180434015095098, 0.15819230372255452]\n",
      "   0.45235 [0.010489677705752376, 309, 9, 4, 0.26859812719811277, 0.5505952519904026, 0.997760724148216, 0.7725700671456237, 0.42948978401559806]\n",
      "   0.45237 [0.010612197743699502, 307, 9, 4, 0.023358931765893435, 0.7982749331736431, 0.8301117096862498, 0.7580012760626589, 0.4804344685872787]\n",
      "   0.45247 [0.010453807545749054, 308, 6, 4, 0.17444909578318588, 0.6560626711670331, 0.837643887167826, 0.7929809973940612, 0.17791763750202785]\n",
      "   0.45251 [0.010572396102918841, 303, 9, 4, 0.1424527895345973, 0.5990739510250099, 0.8169849918309376, 0.9819921073981723, 0.046769996167246815]\n",
      "   0.45257 [0.010551497737679771, 305, 5, 4, 0.27866088140017187, 0.7008400427301447, 0.9827353164466237, 0.8284756159775535, 0.12920415163695972]\n",
      "   0.45264 [0.010557959536950674, 303, 8, 4, 0.09751253845340654, 0.6515582522064995, 0.9836858088310778, 0.6297246583930652, 0.01664744073175584]\n",
      "   0.45277 [0.010325067041456724, 307, 7, 4, 0.372368472274336, 0.6010226581846548, 0.9803961484577516, 0.9228468649730648, 0.3233989386488278]\n",
      "   0.45278 [0.010229891759649872, 310, 9, 4, 0.45381839763281495, 0.6837576128760537, 0.9342280890860706, 0.7020950490568953, 0.16788733283065857]\n",
      "   0.45294 [0.010457016656162773, 303, 6, 4, 0.3361606197277065, 0.9048478948361679, 0.9934072904997915, 0.6142374604162062, 0.4199266720413934]\n",
      "   0.45299 [0.010394726836970854, 301, 5, 4, 0.389563066231656, 0.7660562185701218, 0.8756578823260054, 0.9817677682363232, 0.3696365290504292]\n",
      "     0.453 [0.010280583593662178, 302, 7, 4, 0.11683914968206341, 0.5256936970187299, 0.9283033585416554, 0.7843616601409023, 0.4052150868901359]\n",
      "   0.45301 [0.010143735694610544, 306, 6, 4, 0.26276523565909, 0.5266158255241189, 0.9901847510684569, 0.7109833543875124, 0.17875110244496387]\n",
      "   0.45304 [0.010308585491957217, 301, 5, 4, 0.0001963778684849205, 0.6551862435527294, 0.820641860173271, 0.8506990692266836, 0.40953642388711664]\n",
      "   0.45305 [0.01033593285693411, 304, 8, 4, 0.22882725481816557, 0.9213872810740582, 0.9058881191516513, 0.7303846217337924, 0.4107198347806353]\n",
      "   0.45308 [0.010402968114427168, 302, 8, 4, 0.12889999881128175, 0.9411359950207752, 0.9765481449409755, 0.7379138265878289, 0.17686790761815394]\n",
      "   0.45308 [0.010350164680663966, 300, 6, 4, 0.06789868551150254, 0.7080326932832661, 0.8229880931003059, 0.8413934587761382, 0.3136221110654869]\n",
      "   0.45317 [0.010394516440557715, 301, 9, 4, 0.024426681192493645, 0.9956892181484698, 0.9404327000523407, 0.779914203364449, 0.04576174689492219]\n",
      "   0.45324 [0.010017481692782, 306, 8, 4, 0.4988522126410952, 0.6290985717832165, 0.8873693299877901, 0.7666031968751753, 0.2582079512824734]\n",
      "   0.45333 [0.010082195760586386, 304, 9, 4, 0.2519037762180612, 0.8133387236422112, 0.8104797566426301, 0.7220157642307468, 0.26075235357596416]\n",
      "   0.45341 [0.010055567992499148, 304, 5, 4, 0.4351900796272296, 0.765663871427064, 0.8492990473275075, 0.8247620486062637, 0.1355609923230687]\n",
      "   0.45347 [0.010092233306375249, 300, 6, 4, 0.37848045352972465, 0.6590181126260507, 0.9072504084330699, 0.9608702155592344, 0.002300064788332668]\n"
     ]
    }
   ],
   "source": [
    "sorted_d = sorted(cache.items(), key=lambda x: x[1])\n",
    "temp = []\n",
    "for i in range(len(sorted_d)):\n",
    "    temp.append((sorted_d[i][0], round(sorted_d[i][1],5)))\n",
    "    print('{:10.5} {}'.format(round(sorted_d[i][1],5), sorted_d[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
